<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e00e6e",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       ModelOps demo - Python In-database Using Git\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96f35c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introducción</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "Este es un modelo de prueba.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bb3df",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Pasos dentro del Notebook</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li>Configure el ambiente </li>\n",
    " <li>Conectarse a Vantage</li>\n",
    " <li>Defina la función training</li>\n",
    " <li>Defina la función evaluation</li>\n",
    " <li>Defina la funcion de Scoring</li>\n",
    " <li>Defina la metadata del modelo</li>\n",
    " <li>CHaga commit y push en el Git del modelo</li>\n",
    " <li>Ciclo completo de desarrollot</li>\n",
    " <li>Monitoreo</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9eaa38",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Configure el ambiente</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Instalar e Importar las librerias requeridas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7606f8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.1 Instalación de librerias</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Es importante reininicar el kerner para confirmar el uso de las librerias</b>. Se usa el parametro -q  para evitar el log de la instalacion de las librerias..</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471a044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q teradataml==17.20.0.6 teradatamodelops==7.0.3 matplotlib==3.8.2\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210b4c9-7d3d-4daa-9ada-28f2591351ae",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Hint:</b><i>The easy way to restart the kernel to bring the above installed software into memory is to type zero zero (<b> 0 0 </b>). </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ef23e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.2 Importar Librerias</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cb09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b744bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "import os\n",
    "import getpass\n",
    "import logging\n",
    "import sys\n",
    "##########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf237b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>2. Conectar a Vantage</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80378f0d-a464-40bf-9180-03da16c0e96c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(teradatasql://tdbacen:***@40.71.87.158)\n"
     ]
    }
   ],
   "source": [
    "#%run -i ../UseCases/startup.ipynb\n",
    "eng = create_context(host = '40.71.87.158', username='tdbacen', password = 'tdbacen')\n",
    "\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab4684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Bacen\\\\modelops-demo-models-master\\\\model_definitions\\\\CreditRisk4_RegLogInDb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81eaf79-ccd8-421d-9a75-046607a69a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "execute_sql('''SET query_band='DEMO=Ejemplo para crear proyecto ModelOps;' UPDATE FOR SESSION; ''')\n",
    "\n",
    "# configure byom/val \n",
    "configure.val_install_location = \"VAL\"\n",
    "configure.byom_install_location = \"MLDB\"\n",
    "\n",
    "# Configure el PATH al repositorio local\n",
    "\n",
    "#model_local_path = '.'\n",
    "model_local_path = os.getcwd() \n",
    "directorio = model_local_path+'\\\\model_modules'\n",
    "#res = os.system(f'mkdir -p {model_local_path}\\\\model_modules')  # Para Uniz usar el -p\n",
    "\n",
    "res1 = os.system(f'mkdir  {model_local_path}\\\\artifacts')\n",
    "res = os.system(f'mkdir  {model_local_path}\\\\model_modules')\n",
    "#print(directorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276b9aa-0bb5-461f-b4e1-e6ef4afd3e97",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Crear la tabla</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> Se crea la tabla para almacenar el modelo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a5acfa-9dbd-4e7b-bc5c-1a9f115ca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Aoa_Byom_Models \n",
    "query = '''CREATE SET TABLE Aoa_Byom_Models \n",
    "     (\n",
    "      model_version VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_type VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      project_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      deployed_at TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),\n",
    "      model BLOB(2097088000))\n",
    "UNIQUE PRIMARY INDEX ( model_version );\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('Aoa_Byom_Models')\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba6a4f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> Se crea la tabla para almacenar las predicciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0223483a-5f1b-430d-87f3-db0a8ab2466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Pima_Patient_Predictions\n",
    "query = '''CREATE MULTISET TABLE tdbacen.CreditRisk_prediction  \n",
    "    (\n",
    "    job_id VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "    id BIGINT,\n",
    "    loan_status INTEGER,\n",
    "    json_report VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC)\n",
    "    PRIMARY INDEX (Id);\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('CreditRisk_prediction')\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec57466",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Defina la función Training</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>La funcion training tiene la siguiente estructura </p>\n",
    "\n",
    "```python\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "    \n",
    "    # Su codigo de entrenamiento usando  funciones teradataml \n",
    "    model = <InDB Function>(...)\n",
    "    \n",
    "    # Guarde el modelo\n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")  \n",
    "    \n",
    "    record_training_stats(...)\n",
    "```\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Se puede ejecutar desde CLI o directamente dentro del notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88f6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\n"
     ]
    }
   ],
   "source": [
    "echo $model_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bb236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\\training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path\\model_modules\\training.py\n",
    "from teradataml import (\n",
    "    DataFrame,\n",
    "    GLM,\n",
    "    ScaleFit,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind='barh').set_title('Feature Importance')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    # read training dataset from Teradata and convert to pandas\n",
    "    train_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    print (\"Scaling using InDB Functions... Rev 123456\")\n",
    "    \n",
    "    #scaler = ScaleFit(\n",
    "    #    data=train_df,\n",
    "    #    target_columns = feature_names,\n",
    "    #    scale_method = context.hyperparams[\"scale_method\"],\n",
    "    #    miss_value = context.hyperparams[\"miss_value\"],\n",
    "    #    global_scale = context.hyperparams[\"global_scale\"].lower() in ['true', '1'],\n",
    "    #    multiplier = context.hyperparams[\"multiplier\"],\n",
    "    #    intercept = context.hyperparams[\"intercept\"]\n",
    "    #)\n",
    "\n",
    "\n",
    "    #scaled_train = ScaleTransform(\n",
    "    #    data=train_df,\n",
    "    #    object=scaler.output,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "  #  scaler.output.to_sql(f\"scaler_${context.model_version}\", if_exists=\"replace\")\n",
    "  #  print(\"Saved scaler\")\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    \n",
    "    model = GLM(input_columns= feature_names,\n",
    "                 response_column = target_name,\n",
    "                #data = scaled_train.result, \n",
    "                data = train_df, \n",
    "                family = context.hyperparams[\"family\"],\n",
    "                iter_max = context.hyperparams[\"iter_max\"],\n",
    "               learning_rate = context.hyperparams[\"learning_rate\"],\n",
    "                momentum = context.hyperparams[\"momentum\"]\n",
    "               )\n",
    "    \n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")    \n",
    "    print(\"Saved trained model xyz\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "   \n",
    "    model_pdf = model.result.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    #record_training_stats(\n",
    "    #    train_df,\n",
    "    #    features=feature_names,\n",
    "    #    targets=[target_name],\n",
    "    #    categorical=[target_name],\n",
    "    #    feature_importance=feature_importance,\n",
    "    #    context=context\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1483fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using InDB Functions... Rev 123456\n",
      "Starting training...\n",
      "Saved trained model xyz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebook se define lo siguiente :\n",
    "\n",
    "# define the training dataset \n",
    "#sql = \"\"\"\n",
    "#SELECT \n",
    "#    F.*, D.hasdiabetes\n",
    "#FROM tdbacen.PIMA_PATIENT_FEATURES F \n",
    "#JOIN tdbacen.PIMA_PATIENT_DIAGNOSES D\n",
    "#ON F.patientid = D.patientid\n",
    "#    WHERE D.patientid MOD 5 <> 0\n",
    "#\"\"\"\n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=1 \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "feature_metadata =  {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"aoa_statistics_metadata\"\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"family\": \"BINOMIAL\", \n",
    "    \"learning_rate\": \"OPTIMAL\",\n",
    "    \"momentum\": 0.6,\n",
    "    \"iter_max\": 100,\n",
    "    \n",
    "    \"scale_method\":\"STD\",\n",
    "    \"miss_value\":\"KEEP\",\n",
    "    \"global_scale\":\"False\",\n",
    "    \"multiplier\":\"1\",\n",
    "    \"intercept\":\"0\",\n",
    "    \"initial_eta\": 0.05,\n",
    "    \"local_sgd_iterations\": 10,\n",
    "    \"batch_size\": 50,\n",
    "    \"iter_num_no_change\": 5\n",
    "}\n",
    "\n",
    "entity_key = \"Id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "\n",
    "from aoa import ModelContext, DatasetInfo\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.expanduser(f\"{model_local_path}/model_modules\"))\n",
    "import training\n",
    "training.train(context=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5f3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is E8DF-A8FB\n",
      "\n",
      " Directory of c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\n",
      "\n",
      "09/07/2024  08:56 a.�m.    <DIR>          .\n",
      "09/07/2024  08:56 a.�m.    <DIR>          ..\n",
      "10/07/2024  10:04 a.�m.             5,741 evaluation.py\n",
      "10/07/2024  10:06 a.�m.                98 requirements.txt\n",
      "10/07/2024  10:09 a.�m.             2,978 scoring.py\n",
      "10/07/2024  11:08 a.�m.             3,286 training.py\n",
      "10/07/2024  11:08 a.�m.    <DIR>          __pycache__\n",
      "               4 File(s)         12,103 bytes\n",
      "               3 Dir(s)  587,772,346,368 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Check the generated files\n",
    "!dir  model_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f052a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Defina la función de evaluación</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>La función de evaluación tiene la siguiente estructura :</p>\n",
    "\n",
    "```python\n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model from Vantage\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_evaluation_stats(...)\n",
    "```\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Se puede crear desde CLI  o en el notebook como se muestra a continuación.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e017d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\\evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path\\model_modules\\evaluation.py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform,\n",
    "    ClassificationEvaluator,\n",
    "    ConvertTo,\n",
    "    ROC\n",
    ")\n",
    "from aoa import (\n",
    "    record_evaluation_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind='barh').set_title('Feature Importance')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix(cf, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(cf, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cf.shape[0]):\n",
    "        for j in range(cf.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cf[i, j], va='center', ha='center', size='xx-large')\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix');\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_roc_curve(roc_out, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    auc = roc_out.result.to_pandas().reset_index()['AUC'][0]\n",
    "    roc_results = roc_out.output_data.to_pandas()\n",
    "    plt.plot(roc_results['fpr'], roc_results['tpr'], color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % 0.27)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    test_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    # Scaling the test set\n",
    "    #print (\"Loading scaler...\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_test = ScaleTransform(\n",
    "    #    data=test_df,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_test.result,\n",
    "        newdata=test_df,\n",
    "        accumulate=target_name,\n",
    "        id_column=entity_key,\n",
    "        output_prob=True,\n",
    "        output_responses=['0','1']\n",
    "    )\n",
    "\n",
    "    predicted_data = ConvertTo(\n",
    "        data = predictions.result,\n",
    "        target_columns = [target_name,'prediction'],\n",
    "        target_datatype = [\"INTEGER\"]\n",
    "    )\n",
    "\n",
    "    ClassificationEvaluator_obj = ClassificationEvaluator(\n",
    "        data=predicted_data.result,\n",
    "        observation_column=target_name,\n",
    "        prediction_column='prediction',\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "    metrics_pd = ClassificationEvaluator_obj.output_data.to_pandas()\n",
    "\n",
    "    evaluation = {\n",
    "        'Accuracy': '{:.2f}'.format(metrics_pd.MetricValue[0]),\n",
    "        'Micro-Precision': '{:.2f}'.format(metrics_pd.MetricValue[1]),\n",
    "        'Micro-Recall': '{:.2f}'.format(metrics_pd.MetricValue[2]),\n",
    "        'Micro-F1': '{:.2f}'.format(metrics_pd.MetricValue[3]),\n",
    "        'Macro-Precision': '{:.2f}'.format(metrics_pd.MetricValue[4]),\n",
    "        'Macro-Recall': '{:.2f}'.format(metrics_pd.MetricValue[5]),\n",
    "        'Macro-F1': '{:.2f}'.format(metrics_pd.MetricValue[6]),\n",
    "        'Weighted-Precision': '{:.2f}'.format(metrics_pd.MetricValue[7]),\n",
    "        'Weighted-Recall': '{:.2f}'.format(metrics_pd.MetricValue[8]),\n",
    "        'Weighted-F1': '{:.2f}'.format(metrics_pd.MetricValue[9]),\n",
    "    }\n",
    "\n",
    "    with open(f\"{context.artifact_output_path}/metrics.json\", \"w+\") as f:\n",
    "        json.dump(evaluation, f)\n",
    "        \n",
    "    cm = confusion_matrix(predicted_data.result.to_pandas()['loan_status'], predicted_data.result.to_pandas()['prediction'])\n",
    "    plot_confusion_matrix(cm, f\"{context.artifact_output_path}/confusion_matrix\")\n",
    "\n",
    "    #roc_out = ROC(\n",
    "    #    data=predictions.result,\n",
    "    #    probability_column='prob_1',\n",
    "    #    observation_column=target_name,\n",
    "    #    positive_class='1',\n",
    "    #    num_thresholds=1000\n",
    "    #)\n",
    "    #plot_roc_curve(roc_out, f\"{context.artifact_output_path}/roc_curve\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    model_pdf = model.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    predictions_table = \"predictions_tmp\"\n",
    "    copy_to_sql(df=predicted_data.result, table_name=predictions_table, index=False, if_exists=\"replace\", temporary=True)\n",
    "\n",
    "    # calculate stats if training stats exist\n",
    "    if os.path.exists(f\"{context.artifact_input_path}/data_stats.json\"):\n",
    "        record_evaluation_stats(\n",
    "            features_df=test_df,\n",
    "            predicted_df=DataFrame.from_query(f\"SELECT * FROM {predictions_table}\"),\n",
    "            feature_importance=feature_importance,\n",
    "            context=context\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b9e3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring\n",
      "{'Accuracy': '0.83', 'Micro-Precision': '0.83', 'Micro-Recall': '0.83', 'Micro-F1': '0.83', 'Macro-Precision': '0.78', 'Macro-Recall': '0.66', 'Macro-F1': '0.69', 'Weighted-Precision': '0.82', 'Weighted-Recall': '0.83', 'Weighted-F1': '0.81'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 750x750 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebok se define lo siguiente :\n",
    "\n",
    "# define the evaluation dataset \n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=2\n",
    "\"\"\"\n",
    "\n",
    "entity_key = \"id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    artifact_input_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "import evaluation\n",
    "evaluation.evaluate(context=ctx)\n",
    "\n",
    "# view evaluation results\n",
    "import json\n",
    "with open(f\"{ctx.artifact_output_path}/metrics.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd20501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is E8DF-A8FB\n",
      "\n",
      " Directory of c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\artifacts\n",
      "\n",
      "09/07/2024  01:05 p.�m.    <DIR>          .\n",
      "09/07/2024  01:05 p.�m.    <DIR>          ..\n",
      "10/07/2024  11:09 a.�m.           142,186 confusion_matrix.png\n",
      "10/07/2024  11:09 a.�m.           182,993 feature_importance.png\n",
      "10/07/2024  11:09 a.�m.               242 metrics.json\n",
      "               3 File(s)        325,421 bytes\n",
      "               2 Dir(s)  587,777,990,656 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Check the generated files\n",
    "!dir artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcdfc8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. Defina función de Scoring</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><La función de scoring tiene la siguiente estructura : ></p>\n",
    "\n",
    "```python\n",
    "def score(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_scoring_stats(...)\n",
    "```\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Se puede ejecutar desde  CLI o desde  notebook de la siguiente forma.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77825ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\\scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path\\model_modules\\scoring.py\n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_scoring_stats,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def score(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    features_tdf = DataFrame.from_query(context.dataset_info.sql)\n",
    "    features_pdf = features_tdf.to_pandas(all_rows=True)\n",
    "\n",
    "    # Scaling the scoring set\n",
    "    print (\"Loading scaler...NO\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_features = ScaleTransform(\n",
    "    #    data=features_tdf,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = entity_key\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_features.result,\n",
    "        newdata=features_tdf,\n",
    "        id_column=entity_key\n",
    "    )\n",
    "\n",
    "    predictions_pdf = predictions.result.to_pandas(all_rows=True).rename(columns={\"prediction\": target_name}).astype(int)\n",
    "\n",
    "    print(\"Finished Scoring\")\n",
    "\n",
    "    # store the predictions\n",
    "    predictions_pdf = pd.DataFrame(predictions_pdf, columns=[target_name])\n",
    "    predictions_pdf[entity_key] = features_pdf.index.values\n",
    "    # add job_id column so we know which execution this is from if appended to predictions table\n",
    "    predictions_pdf[\"job_id\"] = context.job_id\n",
    "\n",
    "    # teradataml doesn't match column names on append.. and so to match / use same table schema as for byom predict\n",
    "    # example (see README.md), we must add empty json_report column and change column order manually (v17.0.0.4)\n",
    "    # CREATE MULTISET TABLE pima_patient_predictions\n",
    "    # (\n",
    "    #     job_id VARCHAR(255), -- comes from airflow on job execution\n",
    "    #     PatientId BIGINT,    -- entity key as it is in the source data\n",
    "    #     HasDiabetes BIGINT,   -- if model automatically extracts target\n",
    "    #     json_report CLOB(1048544000) CHARACTER SET UNICODE  -- output of\n",
    "    # )\n",
    "    # PRIMARY INDEX ( job_id );\n",
    "    predictions_pdf[\"json_report\"] = \"\"\n",
    "    predictions_pdf = predictions_pdf[[\"job_id\", entity_key, target_name, \"json_report\"]]\n",
    "    print (context.dataset_info.predictions_database)\n",
    "    print(context.dataset_info.predictions_table)\n",
    "    copy_to_sql(\n",
    "        df=predictions_pdf,\n",
    "        schema_name=context.dataset_info.predictions_database,\n",
    "        table_name=context.dataset_info.predictions_table,\n",
    "        index=False,\n",
    "        if_exists=\"append\"\n",
    "    )\n",
    "    \n",
    "    print(\"Saved predictions in Teradata\")\n",
    "\n",
    "    # calculate stats\n",
    "    #predictions_df = DataFrame.from_query(f\"\"\"\n",
    "    #    SELECT \n",
    "    #        * \n",
    "    #    FROM {context.dataset_info.get_predictions_metadata_fqtn()} \n",
    "    #        WHERE job_id = '{context.job_id}'\n",
    "    #\"\"\")\n",
    "\n",
    "    #record_scoring_stats(features_df=features_tdf, predicted_df=predictions_df, context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d04af97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scaler...NO\n",
      "Scoring\n",
      "Finished Scoring\n",
      "tdbacen\n",
      "CreditRisk_prediction\n",
      "Saved predictions in Teradata\n"
     ]
    }
   ],
   "source": [
    "# Se hace automatico por modelop via CLI / UI. sin embargo para probar el notebook, se puede definir lo siguiente\n",
    "\n",
    "# define the scoring dataset \n",
    "\n",
    "sql = \"\"\"\n",
    "\t     Select * from tdbacen.CreditRisk_dataset\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# where to store predictions\n",
    "predictions = {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"CreditRisk_prediction\"\n",
    "}\n",
    "\n",
    "import uuid\n",
    "job_id=str(uuid.uuid4())\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata,\n",
    "                           predictions=predictions)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"artifacts/\",\n",
    "                   artifact_input_path=\"artifacts/\",\n",
    "                   model_version=\"InDB_v1\",\n",
    "                   model_table=\"model_InDB_v1\",\n",
    "                   job_id=job_id)\n",
    "\n",
    "import scoring\n",
    "scoring.score(context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d57f577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>job_id</th>\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>loan_status</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>20657</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>20188</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>28304</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>8585</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>19719</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>3956</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>14621</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>31791</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>11399</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                     job_id  loan_status json_report\n",
       "id                                                                  \n",
       "20657  6e4c93a3-c050-4b45-a940-21d03340fb14            1            \n",
       "20188  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "28304  6e4c93a3-c050-4b45-a940-21d03340fb14            1            \n",
       "8585   6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "19719  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "3956   6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "14621  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "0      6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "31791  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "11399  6e4c93a3-c050-4b45-a940-21d03340fb14            0            "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame.from_query(f\"SELECT * FROM tdbacen.CreditRisk_prediction WHERE job_id='{job_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (Lo dejo comentariado)\n",
    "#os.system('rm -f artifacts/*')\n",
    "\n",
    "#try:\n",
    "#    db_drop_table('model_InDB_v1')\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table('scaler_InDB_v1')\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table('pima_patient_predictions_tmp')\n",
    "#except: \n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d9a73",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. Define la metadata del modelo</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Ahora crear el archivo de configuración.<br>El archivo de dependencias con sus versiones:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f946e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb/model_modules/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/requirements.txt\n",
    "teradataml==17.20.0.6\n",
    "teradatamodelops==7.0.3\n",
    "pandas==2.1.4\n",
    "scikit-learn==1.3.2\n",
    "matplotlib==3.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af179c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Configure los hiper parametros (Valores x Defecto):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37165d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/config.json\n",
    "{\n",
    "   \"hyperParameters\": {\n",
    "        \"scale_method\":\"STD\",\n",
    "        \"miss_value\":\"KEEP\",\n",
    "        \"global_scale\": \"False\",\n",
    "        \"multiplier\":\"1\",\n",
    "        \"intercept\":\"0\",\n",
    "        \"family\": \"BINOMIAL\", \n",
    "        \"learning_rate\": \"OPTIMAL\",\n",
    "        \"momentum\": 0.80,\n",
    "        \"initial_eta\": 0.05,\n",
    "        \"local_sgd_iterations\": 10,\n",
    "        \"iter_max\": 100,\n",
    "        \"batch_size\": 50,\n",
    "        \"iter_num_no_change\": 5\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4467f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>La configuración del modelo:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "236decde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb/model.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model.json\n",
    "{\n",
    "    \"id\": \"f8df0bec-12d1-4d2d-920f-4448503df82d\",\n",
    "    \"name\": \"Modelo Ejemplo 3\",\n",
    "    \"description\": \"Modelo Ejemplo\",\n",
    "    \"language\": \"python\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b17a7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>7. Commit and Push to Git to let ModelOps manage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Run the command below to commit and push changes to our forked repository, so ModelOps can fetch the changes to the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a45c4ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "!cd $model_local_path/../.. && git add . && git commit -m \"Added Python PIMA InDB GLM demo model 🚀\" && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7cf2a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now that changes are pushed, you can make the lifecycle inside <b>ModelOps User Interface</b>, plan for new trainings, evaluations and scorings. Compare models and operationalize into Production with automated Monitoring and alerting capabilities.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a160f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>8. ModelOps full lifecycle till deployment</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fbc02",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use or Create a Project with the git code repository with the model code, then you should see the model in the catalog already created</p>\n",
    "\n",
    "<img src=\"images/08_01.png\" alt=\"Model Catalog with inDB\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Select the Model and then click Train a new Model. Use default hyper-parameters. This will launch the training job with the training script we generated and pushed to Git.</p>\n",
    "\n",
    "<img src=\"images/08_02.png\" alt=\"Train\"/>\n",
    "\n",
    "<img src=\"images/08_03.png\" alt=\"Train job\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_04.png\" alt=\"Train finished\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When Model is trained a new Model Id is created and you can get inside the Model Lifecycle screen to review artifacts and other details</p>\n",
    "\n",
    "<img src=\"images/08_06.png\" alt=\"Model lifecycle\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's evaluate the Model, click the button and select the evaluation dataset. This will launch the evaluation job with the training script we generated and pushed to Git.</p>\n",
    "\n",
    "<img src=\"images/08_07.png\" alt=\"Evaluation\" width=\"500\" height=\"500\"/> <img src=\"images/08_08.png\" alt=\"Evaluation job\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When evaluation job is finished a Model evaluation Report is generated with the metrics and charts that evaluation script generates</p>\n",
    "\n",
    "<img src=\"images/08_26.png\" alt=\"Model Report\" />\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's approve the model and provide an approval description</p>\n",
    "\n",
    "<img src=\"images/08_09.png\" alt=\"Approval\" />\n",
    "\n",
    "<img src=\"images/08_10.png\" alt=\"Approval description\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The model is ready to be deployed. Let's deploy using a Batch scheduling option - Run it manual</p>\n",
    "\n",
    "<img src=\"images/08_11.png\" alt=\"Deployment Engine\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_12.png\" alt=\"Deployment Publish\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_13.png\" alt=\"Deployment Schedule\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88476c06-359f-41ea-b65e-67327de32ed7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116c610-7119-41f6-973f-349e2081bdda",
   "metadata": {},
   "source": [
    "[![image](images/launchModelOps.png)](/modelops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73db1c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>9. ModelOps Monitoring</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now the model is deployed and a new Deployment appears in the deployment screen</p>\n",
    "\n",
    "\n",
    "<img src=\"images/08_15.png\" alt=\"Deploymet\" />\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You can run jobs manually from here, review history of executions and view the predictions for a specific job</p>\n",
    "\n",
    "<img src=\"images/08_16.png\" alt=\"Deployment Run\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_17.png\" alt=\"Deployment Jobs\" />\n",
    "\n",
    "<img src=\"images/08_18.png\" alt=\"Deployment view\" width=\"500\" height=\"500\" />\n",
    "\n",
    "<img src=\"images/08_19.png\" alt=\"Deployment predictions\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_20.png\" alt=\"Deployment\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>From the Feature Drift and Prediction Drift tabs you can check on the monitoring of the data drift</p>\n",
    "\n",
    "<img src=\"images/08_22.png\" alt=\"Feature Drift\" />\n",
    "\n",
    "<img src=\"images/08_21.png\" alt=\"Prediction Drift\" />\n",
    "\n",
    "<img src=\"images/08_23.png\" alt=\"Performance Monitoring\" />\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>From the Performance Drift, you can review multiple evaluations, let's evaluate the model with a new dataset. We create a new evaluation dataset with this query:</p>\n",
    "    \n",
    "```sql\n",
    "SELECT * FROM pima_patient_diagnoses F WHERE F.patientid MOD 8 <> 0  \n",
    "```\n",
    "\n",
    "<img src=\"images/08_24.png\" alt=\"Evaluate\" width=\"500\" height=\"500\" />\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>and now see the evolution of the metrics</p>\n",
    "\n",
    "<img src=\"images/08_25.png\" alt=\"Metrics monitoring\" />\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "With ModelOps you can close the cycle and review make decisions when you need to replace yor model in production, For example, You could get alerting from Data Drift of Performance Drift and you can create multiple versions and compare them, select a champion and deploy new versions that replace existing in Production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1554f-4c37-4a3a-a333-a96a505dafdf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfe9b7-ab64-43b7-97e8-8c8457269820",
   "metadata": {},
   "source": [
    "[![image](images/launchModelOps.png)](/modelops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046954d-65b1-4939-9ff9-2e12411f3e7e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>10. Cleanup</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b210b57-bbc3-485b-a6cc-fbd01f06253f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If you are done with ModelOps usecase, please uncomment and run the below cleanup section.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bcd8c6-7d73-46e3-8a22-f81c30119256",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e49a6-3cd3-49cd-9cfa-c0342c9d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_drop_table(table_name = 'aoa_byom_models', schema_name = 'demo_user')\n",
    "# db_drop_table(table_name = 'pima_patient_predictions', schema_name = 'demo_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd8630-f040-4583-af23-d0a30f8901ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbc041-b2d5-4926-bae2-0b1cee3d3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../UseCases/run_procedure.py \"call remove_data('DEMO_ModelOps');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f8688-e4e8-46b8-9bba-2c88d9eefe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d459036-095d-4dc9-a082-1575ada88fa9",
   "metadata": {},
   "source": [
    "[<< Back to GIT Project Setup](./06_ModelOps_GIT_Project_Setup.ipynb) | [Continue to GIT PIMA H2OAutoML >>](./08_ModelOps_GIT_PIMA_Python_H2OAutoML.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c179b",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e00e6e",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       ModelOps demo - Python In-database Using Git\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96f35c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introducción</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "Este es un modelo de prueba.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bb3df",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Pasos dentro del Notebook</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li>Configure el ambiente </li>\n",
    " <li>Conectarse a Vantage</li>\n",
    " <li>Defina la función training</li>\n",
    " <li>Defina la función evaluation</li>\n",
    " <li>Defina la funcion de Scoring</li>\n",
    " <li>Defina la metadata del modelo</li>\n",
    " <li>CHaga commit y push en el Git del modelo</li>\n",
    " <li>Ciclo completo de desarrollot</li>\n",
    " <li>Monitoreo</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9eaa38",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Configure el ambiente</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Instalar e Importar las librerias requeridas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7606f8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.1 Instalación de librerias</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Es importante reininicar el kerner para confirmar el uso de las librerias</b>. Se usa el parametro -q  para evitar el log de la instalacion de las librerias..</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471a044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q teradataml==17.20.0.6 teradatamodelops==7.0.3 matplotlib==3.8.2\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210b4c9-7d3d-4daa-9ada-28f2591351ae",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Hint:</b><i>The easy way to restart the kernel to bring the above installed software into memory is to type zero zero (<b> 0 0 </b>). </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ef23e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.2 Importar Librerias</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cb09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b744bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "import os\n",
    "import getpass\n",
    "import logging\n",
    "import sys\n",
    "##########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf237b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>2. Conectar a Vantage</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80378f0d-a464-40bf-9180-03da16c0e96c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(teradatasql://tdbacen:***@40.71.87.158)\n"
     ]
    }
   ],
   "source": [
    "#%run -i ../UseCases/startup.ipynb\n",
    "eng = create_context(host = '40.71.87.158', username='tdbacen', password = 'tdbacen')\n",
    "\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab4684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Bacen\\\\modelops-demo-models-master\\\\model_definitions\\\\CreditRisk4_RegLogInDb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81eaf79-ccd8-421d-9a75-046607a69a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "execute_sql('''SET query_band='DEMO=Ejemplo para crear proyecto ModelOps;' UPDATE FOR SESSION; ''')\n",
    "\n",
    "# configure byom/val \n",
    "configure.val_install_location = \"VAL\"\n",
    "configure.byom_install_location = \"MLDB\"\n",
    "\n",
    "# Configure el PATH al repositorio local\n",
    "\n",
    "#model_local_path = '.'\n",
    "model_local_path = os.getcwd() \n",
    "directorio = model_local_path+'\\\\model_modules'\n",
    "#res = os.system(f'mkdir -p {model_local_path}\\\\model_modules')  # Para Uniz usar el -p\n",
    "\n",
    "res1 = os.system(f'mkdir  {model_local_path}\\\\artifacts')\n",
    "res = os.system(f'mkdir  {model_local_path}\\\\model_modules')\n",
    "#print(directorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276b9aa-0bb5-461f-b4e1-e6ef4afd3e97",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Crear la tabla</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> Se crea la tabla para almacenar el modelo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a5acfa-9dbd-4e7b-bc5c-1a9f115ca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Aoa_Byom_Models \n",
    "query = '''CREATE SET TABLE Aoa_Byom_Models \n",
    "     (\n",
    "      model_version VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_type VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      project_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      deployed_at TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),\n",
    "      model BLOB(2097088000))\n",
    "UNIQUE PRIMARY INDEX ( model_version );\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('Aoa_Byom_Models')\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba6a4f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> Se crea la tabla para almacenar las predicciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0223483a-5f1b-430d-87f3-db0a8ab2466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Pima_Patient_Predictions\n",
    "query = '''CREATE MULTISET TABLE tdbacen.CreditRisk_prediction  \n",
    "    (\n",
    "    job_id VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "    id BIGINT,\n",
    "    loan_status INTEGER,\n",
    "    json_report VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC)\n",
    "    PRIMARY INDEX (Id);\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('CreditRisk_prediction')\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec57466",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Defina la función Training</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>La funcion training tiene la siguiente estructura </p>\n",
    "\n",
    "```python\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "    \n",
    "    # Su codigo de entrenamiento usando  funciones teradataml \n",
    "    model = <InDB Function>(...)\n",
    "    \n",
    "    # Guarde el modelo\n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")  \n",
    "    \n",
    "    record_training_stats(...)\n",
    "```\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Se puede ejecutar desde CLI o directamente dentro del notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88f6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\n"
     ]
    }
   ],
   "source": [
    "echo $model_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bb236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\\training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path\\model_modules\\training.py\n",
    "from teradataml import (\n",
    "    DataFrame,\n",
    "    GLM,\n",
    "    ScaleFit,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind='barh').set_title('Feature Importance')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    # read training dataset from Teradata and convert to pandas\n",
    "    train_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    print (\"Scaling using InDB Functions... Rev 123456\")\n",
    "    \n",
    "    #scaler = ScaleFit(\n",
    "    #    data=train_df,\n",
    "    #    target_columns = feature_names,\n",
    "    #    scale_method = context.hyperparams[\"scale_method\"],\n",
    "    #    miss_value = context.hyperparams[\"miss_value\"],\n",
    "    #    global_scale = context.hyperparams[\"global_scale\"].lower() in ['true', '1'],\n",
    "    #    multiplier = context.hyperparams[\"multiplier\"],\n",
    "    #    intercept = context.hyperparams[\"intercept\"]\n",
    "    #)\n",
    "\n",
    "\n",
    "    #scaled_train = ScaleTransform(\n",
    "    #    data=train_df,\n",
    "    #    object=scaler.output,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "  #  scaler.output.to_sql(f\"scaler_${context.model_version}\", if_exists=\"replace\")\n",
    "  #  print(\"Saved scaler\")\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    \n",
    "    model = GLM(input_columns= feature_names,\n",
    "                 response_column = target_name,\n",
    "                #data = scaled_train.result, \n",
    "                data = train_df, \n",
    "                family = context.hyperparams[\"family\"],\n",
    "                iter_max = context.hyperparams[\"iter_max\"],\n",
    "               learning_rate = context.hyperparams[\"learning_rate\"],\n",
    "                momentum = context.hyperparams[\"momentum\"]\n",
    "               )\n",
    "    \n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")    \n",
    "    print(\"Saved trained model xyz\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "   \n",
    "    model_pdf = model.result.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    #record_training_stats(\n",
    "    #    train_df,\n",
    "    #    features=feature_names,\n",
    "    #    targets=[target_name],\n",
    "    #    categorical=[target_name],\n",
    "    #    feature_importance=feature_importance,\n",
    "    #    context=context\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1483fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using InDB Functions... Rev 123456\n",
      "Starting training...\n",
      "Saved trained model xyz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebook se define lo siguiente :\n",
    "\n",
    "# define the training dataset \n",
    "#sql = \"\"\"\n",
    "#SELECT \n",
    "#    F.*, D.hasdiabetes\n",
    "#FROM tdbacen.PIMA_PATIENT_FEATURES F \n",
    "#JOIN tdbacen.PIMA_PATIENT_DIAGNOSES D\n",
    "#ON F.patientid = D.patientid\n",
    "#    WHERE D.patientid MOD 5 <> 0\n",
    "#\"\"\"\n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=1 \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "feature_metadata =  {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"aoa_statistics_metadata\"\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"family\": \"BINOMIAL\", \n",
    "    \"learning_rate\": \"OPTIMAL\",\n",
    "    \"momentum\": 0.6,\n",
    "    \"iter_max\": 100,\n",
    "    \n",
    "    \"scale_method\":\"STD\",\n",
    "    \"miss_value\":\"KEEP\",\n",
    "    \"global_scale\":\"False\",\n",
    "    \"multiplier\":\"1\",\n",
    "    \"intercept\":\"0\",\n",
    "    \"initial_eta\": 0.05,\n",
    "    \"local_sgd_iterations\": 10,\n",
    "    \"batch_size\": 50,\n",
    "    \"iter_num_no_change\": 5\n",
    "}\n",
    "\n",
    "entity_key = \"Id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "\n",
    "from aoa import ModelContext, DatasetInfo\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.expanduser(f\"{model_local_path}/model_modules\"))\n",
    "import training\n",
    "training.train(context=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5f3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is E8DF-A8FB\n",
      "\n",
      " Directory of c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\n",
      "\n",
      "09/07/2024  08:56 a.�m.    <DIR>          .\n",
      "09/07/2024  08:56 a.�m.    <DIR>          ..\n",
      "10/07/2024  10:04 a.�m.             5,741 evaluation.py\n",
      "10/07/2024  10:06 a.�m.                98 requirements.txt\n",
      "10/07/2024  10:09 a.�m.             2,978 scoring.py\n",
      "10/07/2024  11:08 a.�m.             3,286 training.py\n",
      "10/07/2024  11:08 a.�m.    <DIR>          __pycache__\n",
      "               4 File(s)         12,103 bytes\n",
      "               3 Dir(s)  587,772,346,368 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Check the generated files\n",
    "!dir  model_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f052a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Defina la función de evaluación</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>La función de evaluación tiene la siguiente estructura :</p>\n",
    "\n",
    "```python\n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model from Vantage\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_evaluation_stats(...)\n",
    "```\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Se puede crear desde CLI  o en el notebook como se muestra a continuación.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e017d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\\evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path\\model_modules\\evaluation.py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform,\n",
    "    ClassificationEvaluator,\n",
    "    ConvertTo,\n",
    "    ROC\n",
    ")\n",
    "from aoa import (\n",
    "    record_evaluation_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind='barh').set_title('Feature Importance')\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix(cf, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(cf, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cf.shape[0]):\n",
    "        for j in range(cf.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cf[i, j], va='center', ha='center', size='xx-large')\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix');\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_roc_curve(roc_out, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    auc = roc_out.result.to_pandas().reset_index()['AUC'][0]\n",
    "    roc_results = roc_out.output_data.to_pandas()\n",
    "    plt.plot(roc_results['fpr'], roc_results['tpr'], color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % 0.27)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    test_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    # Scaling the test set\n",
    "    #print (\"Loading scaler...\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_test = ScaleTransform(\n",
    "    #    data=test_df,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_test.result,\n",
    "        newdata=test_df,\n",
    "        accumulate=target_name,\n",
    "        id_column=entity_key,\n",
    "        output_prob=True,\n",
    "        output_responses=['0','1']\n",
    "    )\n",
    "\n",
    "    predicted_data = ConvertTo(\n",
    "        data = predictions.result,\n",
    "        target_columns = [target_name,'prediction'],\n",
    "        target_datatype = [\"INTEGER\"]\n",
    "    )\n",
    "\n",
    "    ClassificationEvaluator_obj = ClassificationEvaluator(\n",
    "        data=predicted_data.result,\n",
    "        observation_column=target_name,\n",
    "        prediction_column='prediction',\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "    metrics_pd = ClassificationEvaluator_obj.output_data.to_pandas()\n",
    "\n",
    "    evaluation = {\n",
    "        'Accuracy': '{:.2f}'.format(metrics_pd.MetricValue[0]),\n",
    "        'Micro-Precision': '{:.2f}'.format(metrics_pd.MetricValue[1]),\n",
    "        'Micro-Recall': '{:.2f}'.format(metrics_pd.MetricValue[2]),\n",
    "        'Micro-F1': '{:.2f}'.format(metrics_pd.MetricValue[3]),\n",
    "        'Macro-Precision': '{:.2f}'.format(metrics_pd.MetricValue[4]),\n",
    "        'Macro-Recall': '{:.2f}'.format(metrics_pd.MetricValue[5]),\n",
    "        'Macro-F1': '{:.2f}'.format(metrics_pd.MetricValue[6]),\n",
    "        'Weighted-Precision': '{:.2f}'.format(metrics_pd.MetricValue[7]),\n",
    "        'Weighted-Recall': '{:.2f}'.format(metrics_pd.MetricValue[8]),\n",
    "        'Weighted-F1': '{:.2f}'.format(metrics_pd.MetricValue[9]),\n",
    "    }\n",
    "\n",
    "    with open(f\"{context.artifact_output_path}/metrics.json\", \"w+\") as f:\n",
    "        json.dump(evaluation, f)\n",
    "        \n",
    "    cm = confusion_matrix(predicted_data.result.to_pandas()['loan_status'], predicted_data.result.to_pandas()['prediction'])\n",
    "    plot_confusion_matrix(cm, f\"{context.artifact_output_path}/confusion_matrix\")\n",
    "\n",
    "    #roc_out = ROC(\n",
    "    #    data=predictions.result,\n",
    "    #    probability_column='prob_1',\n",
    "    #    observation_column=target_name,\n",
    "    #    positive_class='1',\n",
    "    #    num_thresholds=1000\n",
    "    #)\n",
    "    #plot_roc_curve(roc_out, f\"{context.artifact_output_path}/roc_curve\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    model_pdf = model.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    predictions_table = \"predictions_tmp\"\n",
    "    copy_to_sql(df=predicted_data.result, table_name=predictions_table, index=False, if_exists=\"replace\", temporary=True)\n",
    "\n",
    "    # calculate stats if training stats exist\n",
    "    if os.path.exists(f\"{context.artifact_input_path}/data_stats.json\"):\n",
    "        record_evaluation_stats(\n",
    "            features_df=test_df,\n",
    "            predicted_df=DataFrame.from_query(f\"SELECT * FROM {predictions_table}\"),\n",
    "            feature_importance=feature_importance,\n",
    "            context=context\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b9e3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring\n",
      "{'Accuracy': '0.83', 'Micro-Precision': '0.83', 'Micro-Recall': '0.83', 'Micro-F1': '0.83', 'Macro-Precision': '0.78', 'Macro-Recall': '0.66', 'Macro-F1': '0.69', 'Weighted-Precision': '0.82', 'Weighted-Recall': '0.83', 'Weighted-F1': '0.81'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 750x750 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebok se define lo siguiente :\n",
    "\n",
    "# define the evaluation dataset \n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=2\n",
    "\"\"\"\n",
    "\n",
    "entity_key = \"id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    artifact_input_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "import evaluation\n",
    "evaluation.evaluate(context=ctx)\n",
    "\n",
    "# view evaluation results\n",
    "import json\n",
    "with open(f\"{ctx.artifact_output_path}/metrics.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd20501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is E8DF-A8FB\n",
      "\n",
      " Directory of c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\artifacts\n",
      "\n",
      "09/07/2024  01:05 p.�m.    <DIR>          .\n",
      "09/07/2024  01:05 p.�m.    <DIR>          ..\n",
      "10/07/2024  11:09 a.�m.           142,186 confusion_matrix.png\n",
      "10/07/2024  11:09 a.�m.           182,993 feature_importance.png\n",
      "10/07/2024  11:09 a.�m.               242 metrics.json\n",
      "               3 File(s)        325,421 bytes\n",
      "               2 Dir(s)  587,777,990,656 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Check the generated files\n",
    "!dir artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcdfc8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. Defina función de Scoring</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><La función de scoring tiene la siguiente estructura : ></p>\n",
    "\n",
    "```python\n",
    "def score(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_scoring_stats(...)\n",
    "```\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Se puede ejecutar desde  CLI o desde  notebook de la siguiente forma.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77825ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb\\model_modules\\scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path\\model_modules\\scoring.py\n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_scoring_stats,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def score(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    features_tdf = DataFrame.from_query(context.dataset_info.sql)\n",
    "    features_pdf = features_tdf.to_pandas(all_rows=True)\n",
    "\n",
    "    # Scaling the scoring set\n",
    "    print (\"Loading scaler...NO\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_features = ScaleTransform(\n",
    "    #    data=features_tdf,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = entity_key\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_features.result,\n",
    "        newdata=features_tdf,\n",
    "        id_column=entity_key\n",
    "    )\n",
    "\n",
    "    predictions_pdf = predictions.result.to_pandas(all_rows=True).rename(columns={\"prediction\": target_name}).astype(int)\n",
    "\n",
    "    print(\"Finished Scoring\")\n",
    "\n",
    "    # store the predictions\n",
    "    predictions_pdf = pd.DataFrame(predictions_pdf, columns=[target_name])\n",
    "    predictions_pdf[entity_key] = features_pdf.index.values\n",
    "    # add job_id column so we know which execution this is from if appended to predictions table\n",
    "    predictions_pdf[\"job_id\"] = context.job_id\n",
    "\n",
    "    # teradataml doesn't match column names on append.. and so to match / use same table schema as for byom predict\n",
    "    # example (see README.md), we must add empty json_report column and change column order manually (v17.0.0.4)\n",
    "    # CREATE MULTISET TABLE pima_patient_predictions\n",
    "    # (\n",
    "    #     job_id VARCHAR(255), -- comes from airflow on job execution\n",
    "    #     PatientId BIGINT,    -- entity key as it is in the source data\n",
    "    #     HasDiabetes BIGINT,   -- if model automatically extracts target\n",
    "    #     json_report CLOB(1048544000) CHARACTER SET UNICODE  -- output of\n",
    "    # )\n",
    "    # PRIMARY INDEX ( job_id );\n",
    "    predictions_pdf[\"json_report\"] = \"\"\n",
    "    predictions_pdf = predictions_pdf[[\"job_id\", entity_key, target_name, \"json_report\"]]\n",
    "    print (context.dataset_info.predictions_database)\n",
    "    print(context.dataset_info.predictions_table)\n",
    "    copy_to_sql(\n",
    "        df=predictions_pdf,\n",
    "        schema_name=context.dataset_info.predictions_database,\n",
    "        table_name=context.dataset_info.predictions_table,\n",
    "        index=False,\n",
    "        if_exists=\"append\"\n",
    "    )\n",
    "    \n",
    "    print(\"Saved predictions in Teradata\")\n",
    "\n",
    "    # calculate stats\n",
    "    #predictions_df = DataFrame.from_query(f\"\"\"\n",
    "    #    SELECT \n",
    "    #        * \n",
    "    #    FROM {context.dataset_info.get_predictions_metadata_fqtn()} \n",
    "    #        WHERE job_id = '{context.job_id}'\n",
    "    #\"\"\")\n",
    "\n",
    "    #record_scoring_stats(features_df=features_tdf, predicted_df=predictions_df, context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d04af97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scaler...NO\n",
      "Scoring\n",
      "Finished Scoring\n",
      "tdbacen\n",
      "CreditRisk_prediction\n",
      "Saved predictions in Teradata\n"
     ]
    }
   ],
   "source": [
    "# Se hace automatico por modelop via CLI / UI. sin embargo para probar el notebook, se puede definir lo siguiente\n",
    "\n",
    "# define the scoring dataset \n",
    "\n",
    "sql = \"\"\"\n",
    "\t     Select * from tdbacen.CreditRisk_dataset\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# where to store predictions\n",
    "predictions = {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"CreditRisk_prediction\"\n",
    "}\n",
    "\n",
    "import uuid\n",
    "job_id=str(uuid.uuid4())\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata,\n",
    "                           predictions=predictions)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"artifacts/\",\n",
    "                   artifact_input_path=\"artifacts/\",\n",
    "                   model_version=\"InDB_v1\",\n",
    "                   model_table=\"model_InDB_v1\",\n",
    "                   job_id=job_id)\n",
    "\n",
    "import scoring\n",
    "scoring.score(context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d57f577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>job_id</th>\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>loan_status</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>20657</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>20188</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>28304</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>8585</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>19719</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>3956</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>14621</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>31791</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6e4c93a3-c050-4b45-a940-21d03340fb14</td>\n",
       "\t\t<td>11399</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                     job_id  loan_status json_report\n",
       "id                                                                  \n",
       "20657  6e4c93a3-c050-4b45-a940-21d03340fb14            1            \n",
       "20188  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "28304  6e4c93a3-c050-4b45-a940-21d03340fb14            1            \n",
       "8585   6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "19719  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "3956   6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "14621  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "0      6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "31791  6e4c93a3-c050-4b45-a940-21d03340fb14            0            \n",
       "11399  6e4c93a3-c050-4b45-a940-21d03340fb14            0            "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame.from_query(f\"SELECT * FROM tdbacen.CreditRisk_prediction WHERE job_id='{job_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (Lo dejo comentariado)\n",
    "#os.system('rm -f artifacts/*')\n",
    "\n",
    "#try:\n",
    "#    db_drop_table('model_InDB_v1')\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table('scaler_InDB_v1')\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table('pima_patient_predictions_tmp')\n",
    "#except: \n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d9a73",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. Define la metadata del modelo</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Ahora crear el archivo de configuración.<br>El archivo de dependencias con sus versiones:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f946e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb/model_modules/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/requirements.txt\n",
    "teradataml==17.20.0.6\n",
    "teradatamodelops==7.0.3\n",
    "pandas==2.1.4\n",
    "scikit-learn==1.3.2\n",
    "matplotlib==3.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af179c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Configure los hiper parametros (Valores x Defecto):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37165d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/config.json\n",
    "{\n",
    "   \"hyperParameters\": {\n",
    "        \"scale_method\":\"STD\",\n",
    "        \"miss_value\":\"KEEP\",\n",
    "        \"global_scale\": \"False\",\n",
    "        \"multiplier\":\"1\",\n",
    "        \"intercept\":\"0\",\n",
    "        \"family\": \"BINOMIAL\", \n",
    "        \"learning_rate\": \"OPTIMAL\",\n",
    "        \"momentum\": 0.80,\n",
    "        \"initial_eta\": 0.05,\n",
    "        \"local_sgd_iterations\": 10,\n",
    "        \"iter_max\": 100,\n",
    "        \"batch_size\": 50,\n",
    "        \"iter_num_no_change\": 5\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4467f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>La configuración del modelo:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "236decde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting c:\\Bacen\\modelops-demo-models-master\\model_definitions\\CreditRisk4_RegLogInDb/model.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model.json\n",
    "{\n",
    "    \"id\": \"f8df0bec-12d1-4d2d-920f-4448503df82d\",\n",
    "    \"name\": \"Modelo Ejemplo 3\",\n",
    "    \"description\": \"Modelo Ejemplo\",\n",
    "    \"language\": \"python\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b17a7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>7. Commit and Push to Git to let ModelOps manage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Run the command below to commit and push changes to our forked repository, so ModelOps can fetch the changes to the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a45c4ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "!cd $model_local_path/../.. && git add . && git commit -m \"Added Python PIMA InDB GLM demo model 🚀\" && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7cf2a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now that changes are pushed, you can make the lifecycle inside <b>ModelOps User Interface</b>, plan for new trainings, evaluations and scorings. Compare models and operationalize into Production with automated Monitoring and alerting capabilities.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a160f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>8. ModelOps full lifecycle till deployment</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fbc02",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use or Create a Project with the git code repository with the model code, then you should see the model in the catalog already created</p>\n",
    "\n",
    "<img src=\"images/08_01.png\" alt=\"Model Catalog with inDB\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Select the Model and then click Train a new Model. Use default hyper-parameters. This will launch the training job with the training script we generated and pushed to Git.</p>\n",
    "\n",
    "<img src=\"images/08_02.png\" alt=\"Train\"/>\n",
    "\n",
    "<img src=\"images/08_03.png\" alt=\"Train job\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_04.png\" alt=\"Train finished\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When Model is trained a new Model Id is created and you can get inside the Model Lifecycle screen to review artifacts and other details</p>\n",
    "\n",
    "<img src=\"images/08_06.png\" alt=\"Model lifecycle\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's evaluate the Model, click the button and select the evaluation dataset. This will launch the evaluation job with the training script we generated and pushed to Git.</p>\n",
    "\n",
    "<img src=\"images/08_07.png\" alt=\"Evaluation\" width=\"500\" height=\"500\"/> <img src=\"images/08_08.png\" alt=\"Evaluation job\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>When evaluation job is finished a Model evaluation Report is generated with the metrics and charts that evaluation script generates</p>\n",
    "\n",
    "<img src=\"images/08_26.png\" alt=\"Model Report\" />\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's approve the model and provide an approval description</p>\n",
    "\n",
    "<img src=\"images/08_09.png\" alt=\"Approval\" />\n",
    "\n",
    "<img src=\"images/08_10.png\" alt=\"Approval description\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The model is ready to be deployed. Let's deploy using a Batch scheduling option - Run it manual</p>\n",
    "\n",
    "<img src=\"images/08_11.png\" alt=\"Deployment Engine\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_12.png\" alt=\"Deployment Publish\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_13.png\" alt=\"Deployment Schedule\" width=\"500\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88476c06-359f-41ea-b65e-67327de32ed7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116c610-7119-41f6-973f-349e2081bdda",
   "metadata": {},
   "source": [
    "[![image](images/launchModelOps.png)](/modelops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73db1c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>9. ModelOps Monitoring</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now the model is deployed and a new Deployment appears in the deployment screen</p>\n",
    "\n",
    "\n",
    "<img src=\"images/08_15.png\" alt=\"Deploymet\" />\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You can run jobs manually from here, review history of executions and view the predictions for a specific job</p>\n",
    "\n",
    "<img src=\"images/08_16.png\" alt=\"Deployment Run\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_17.png\" alt=\"Deployment Jobs\" />\n",
    "\n",
    "<img src=\"images/08_18.png\" alt=\"Deployment view\" width=\"500\" height=\"500\" />\n",
    "\n",
    "<img src=\"images/08_19.png\" alt=\"Deployment predictions\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src=\"images/08_20.png\" alt=\"Deployment\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>From the Feature Drift and Prediction Drift tabs you can check on the monitoring of the data drift</p>\n",
    "\n",
    "<img src=\"images/08_22.png\" alt=\"Feature Drift\" />\n",
    "\n",
    "<img src=\"images/08_21.png\" alt=\"Prediction Drift\" />\n",
    "\n",
    "<img src=\"images/08_23.png\" alt=\"Performance Monitoring\" />\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>From the Performance Drift, you can review multiple evaluations, let's evaluate the model with a new dataset. We create a new evaluation dataset with this query:</p>\n",
    "    \n",
    "```sql\n",
    "SELECT * FROM pima_patient_diagnoses F WHERE F.patientid MOD 8 <> 0  \n",
    "```\n",
    "\n",
    "<img src=\"images/08_24.png\" alt=\"Evaluate\" width=\"500\" height=\"500\" />\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>and now see the evolution of the metrics</p>\n",
    "\n",
    "<img src=\"images/08_25.png\" alt=\"Metrics monitoring\" />\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "With ModelOps you can close the cycle and review make decisions when you need to replace yor model in production, For example, You could get alerting from Data Drift of Performance Drift and you can create multiple versions and compare them, select a champion and deploy new versions that replace existing in Production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1554f-4c37-4a3a-a333-a96a505dafdf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfe9b7-ab64-43b7-97e8-8c8457269820",
   "metadata": {},
   "source": [
    "[![image](images/launchModelOps.png)](/modelops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046954d-65b1-4939-9ff9-2e12411f3e7e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = 'font-size:20px;font-family:Arial;color:#00233C'>10. Cleanup</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b210b57-bbc3-485b-a6cc-fbd01f06253f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If you are done with ModelOps usecase, please uncomment and run the below cleanup section.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bcd8c6-7d73-46e3-8a22-f81c30119256",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e49a6-3cd3-49cd-9cfa-c0342c9d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_drop_table(table_name = 'aoa_byom_models', schema_name = 'demo_user')\n",
    "# db_drop_table(table_name = 'pima_patient_predictions', schema_name = 'demo_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd8630-f040-4583-af23-d0a30f8901ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbc041-b2d5-4926-bae2-0b1cee3d3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../UseCases/run_procedure.py \"call remove_data('DEMO_ModelOps');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f8688-e4e8-46b8-9bba-2c88d9eefe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d459036-095d-4dc9-a082-1575ada88fa9",
   "metadata": {},
   "source": [
    "[<< Back to GIT Project Setup](./06_ModelOps_GIT_Project_Setup.ipynb) | [Continue to GIT PIMA H2OAutoML >>](./08_ModelOps_GIT_PIMA_Python_H2OAutoML.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c179b",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> bca332df12e830c02a4513183c003cf8be5a285d
