{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e00e6e",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style=\"font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;\">\n",
    "       ModelOps demo - Python In-database Using Git\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96f35c",
   "metadata": {},
   "source": [
    "<p style = \"font-size:20px;font-family:Arial;color:#00233C\"><b>Introducción</b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">\n",
    "Este es un modelo de prueba.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bb3df",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>Pasos dentro del Notebook</b></p>\n",
    "<ol style = \"font-size:16px;font-family:Arial;color:#00233C\">\n",
    "<li>Configure el ambiente </li>\n",
    " <li>Conectarse a Vantage</li>\n",
    " <li>Defina la función training</li>\n",
    " <li>Defina la función evaluation</li>\n",
    " <li>Defina la funcion de Scoring</li>\n",
    " <li>Defina la metadata del modelo</li>\n",
    " <li>CHaga commit y push en el Git del modelo</li>\n",
    " <li>Ciclo completo de desarrollot</li>\n",
    " <li>Monitoreo</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9eaa38",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">1. Configure el ambiente</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Instalar e Importar las librerias requeridas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7606f8",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>1.1 Instalación de librerias</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"><b>Es importante reininicar el kerner para confirmar el uso de las librerias</b>. Se usa el parametro -q  para evitar el log de la instalacion de las librerias..</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471a044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q teradataml==17.20.0.6 teradatamodelops==7.0.3 matplotlib==3.8.2\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210b4c9-7d3d-4daa-9ada-28f2591351ae",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"><b>Hint:</b><i>The easy way to restart the kernel to bring the above installed software into memory is to type zero zero (<b> 0 0 </b>). </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ef23e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>1.2 Importar Librerias</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3cb09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b744bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "import os\n",
    "import getpass\n",
    "import logging\n",
    "import sys\n",
    "##########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf237b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">2. Conectar a Vantage</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80378f0d-a464-40bf-9180-03da16c0e96c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(teradatasql://tdbacen:***@40.71.87.158)\n"
     ]
    }
   ],
   "source": [
    "#%run -i ../UseCases/startup.ipynb\n",
    "eng = create_context(host = \"40.71.87.158\", username=\"tdbacen\", password = \"tdbacen\")\n",
    "\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab4684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81eaf79-ccd8-421d-9a75-046607a69a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "execute_sql('''SET query_band='DEMO=Ejemplo para crear proyecto ModelOps;' UPDATE FOR SESSION; ''')\n",
    "\n",
    "# configure byom/val \n",
    "configure.val_install_location = \"VAL\"\n",
    "configure.byom_install_location = \"MLDB\"\n",
    "\n",
    "# Configure el PATH al repositorio local\n",
    "\n",
    "#model_local_path = \".\"\n",
    "model_local_path = os.getcwd() \n",
    "res1 = os.system(f\"mkdir -p {model_local_path}/artifacts\")  # Para Unix usar el -p y /\n",
    "res = os.system(f\"mkdir -p {model_local_path}/model_modules\")  # Para Unix usar el -p y /\n",
    "\n",
    "#res1 = os.system(f\"mkdir  {model_local_path}\\\\artifacts\")\n",
    "#res = os.system(f\"mkdir  {model_local_path}\\\\model_modules\") # Para Windows quitar el -p y usar \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276b9aa-0bb5-461f-b4e1-e6ef4afd3e97",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>Crear la tabla</b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"> Se crea la tabla para almacenar el modelo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a5acfa-9dbd-4e7b-bc5c-1a9f115ca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Aoa_Byom_Models \n",
    "query = \"\"\"CREATE SET TABLE Aoa_Byom_Models \n",
    "     (\n",
    "      model_version VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_type VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      project_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      deployed_at TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),\n",
    "      model BLOB(2097088000))\n",
    "UNIQUE PRIMARY INDEX ( model_version );\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table(\"Aoa_Byom_Models\")\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba6a4f",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"> Se crea la tabla para almacenar las predicciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0223483a-5f1b-430d-87f3-db0a8ab2466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Pima_Patient_Predictions\n",
    "query = \"\"\"CREATE MULTISET TABLE tdbacen.CreditRisk_prediction  ,FALLBACK ,\n",
    "    NO BEFORE JOURNAL,\n",
    "    NO AFTER JOURNAL,\n",
    "    CHECKSUM = DEFAULT,\n",
    "    DEFAULT MERGEBLOCKRATIO,\n",
    "    MAP = TD_MAP1\n",
    "    (\n",
    "        job_id VARCHAR(1024) ,\n",
    "        id BIGINT,\n",
    "        loan_status INTEGER,\n",
    "         json_report VARCHAR(1024) \n",
    "    )\n",
    "    PRIMARY INDEX ( id );;\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table(\"CreditRisk_prediction\")\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec57466",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">3. Defina la función Training</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">La funcion training tiene la siguiente estructura </p>\n",
    "\n",
    "```python\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "    \n",
    "    # Su codigo de entrenamiento usando  funciones teradataml \n",
    "    model = <InDB Function>(...)\n",
    "    \n",
    "    # Guarde el modelo\n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")  \n",
    "    \n",
    "    record_training_stats(...)\n",
    "```\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Se puede ejecutar desde CLI o directamente dentro del notebook.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fc1b7-011c-4202-b2c7-97b78f8da2c3",
   "metadata": {},
   "source": [
    "!echo $model_local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563ae03-75c9-4434-ade0-b7d84bcc31fd",
   "metadata": {},
   "source": [
    "La siguente celda en Windows cambia por = %%wwritefile $model_local_path\\model_modules\\training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51bb236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/training.py \n",
    "from teradataml import (\n",
    "    DataFrame,\n",
    "    GLM,\n",
    "    ScaleFit,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind=\"barh\").set_title(\"Feature Importance\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    # read training dataset from Teradata and convert to pandas\n",
    "    train_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    print (\"Scaling using InDB Functions... Rev 1234567\")\n",
    "    \n",
    "    #scaler = ScaleFit(\n",
    "    #    data=train_df,\n",
    "    #    target_columns = feature_names,\n",
    "    #    scale_method = context.hyperparams[\"scale_method\"],\n",
    "    #    miss_value = context.hyperparams[\"miss_value\"],\n",
    "    #    global_scale = context.hyperparams[\"global_scale\"].lower() in [\"true\", \"1\"],\n",
    "    #    multiplier = context.hyperparams[\"multiplier\"],\n",
    "    #    intercept = context.hyperparams[\"intercept\"]\n",
    "    #)\n",
    "\n",
    "\n",
    "    #scaled_train = ScaleTransform(\n",
    "    #    data=train_df,\n",
    "    #    object=scaler.output,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "  #  scaler.output.to_sql(f\"scaler_${context.model_version}\", if_exists=\"replace\")\n",
    "  #  print(\"Saved scaler\")\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    \n",
    "    model = GLM(input_columns= feature_names,\n",
    "                 response_column = target_name,\n",
    "                #data = scaled_train.result, \n",
    "                data = train_df, \n",
    "                family = context.hyperparams[\"family\"],\n",
    "                iter_max = context.hyperparams[\"iter_max\"],\n",
    "               learning_rate = context.hyperparams[\"learning_rate\"],\n",
    "                momentum = context.hyperparams[\"momentum\"]\n",
    "               )\n",
    "    \n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")    \n",
    "    print(\"Saved trained model xyz\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    \n",
    "    model_pdf = model.result.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    print(feature_names)\n",
    "    print(target_name)\n",
    "    print(feature_importance)\n",
    "    print(context)\n",
    "    \n",
    "    #record_training_stats(\n",
    "    #    train_df,\n",
    "    #    features=feature_names,\n",
    "    #    targets=[target_name],\n",
    "    #    categorical=[target_name],\n",
    "    #    feature_importance=feature_importance,\n",
    "    #    context=context\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa3c146-c31c-4bfb-b74c-8f1476714987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1483fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using InDB Functions... Rev 1234567\n",
      "Starting training...\n",
      "Saved trained model xyz\n",
      "['person_income', 'loan_amnt']\n",
      "loan_status\n",
      "{'loan_amnt': 1000.0, 'person_income': 0.0}\n",
      "<aoa.context.model_context.ModelContext object at 0x7f5417e670a0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebook se define lo siguiente :\n",
    "\n",
    "# define the training dataset \n",
    "#sql = \"\"\"\n",
    "#SELECT \n",
    "#    F.*, D.hasdiabetes\n",
    "#FROM tdbacen.PIMA_PATIENT_FEATURES F \n",
    "#JOIN tdbacen.PIMA_PATIENT_DIAGNOSES D\n",
    "#ON F.patientid = D.patientid\n",
    "#    WHERE D.patientid MOD 5 <> 0\n",
    "#\"\"\"\n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=1 \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "feature_metadata =  {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"riesgos_statistics_metadata\"\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"family\": \"BINOMIAL\", \n",
    "    \"learning_rate\": \"OPTIMAL\",\n",
    "    \"momentum\": 0.6,\n",
    "    \"iter_max\": 100,\n",
    "    \n",
    "    \"scale_method\":\"STD\",\n",
    "    \"miss_value\":\"KEEP\",\n",
    "    \"global_scale\":\"False\",\n",
    "    \"multiplier\":\"1\",\n",
    "    \"intercept\":\"0\",\n",
    "    \"initial_eta\": 0.05,\n",
    "    \"local_sgd_iterations\": 10,\n",
    "    \"batch_size\": 50,\n",
    "    \"iter_num_no_change\": 5\n",
    "}\n",
    "\n",
    "entity_key = \"Id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "#target_names = [\"loan_status\"]\n",
    "#feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "feature_names = [\"person_income\",\"loan_amnt\"]\n",
    "#, \"loan_intent_3\", \"loan_grade_5\", \"cb_person_default_on_file_0\", \"loan_grade_4\", \"person_home_ownership_3\", \"loan_amnt\", \"loan_intent_0\", \"person_home_ownership_0\", \"loan_grade_6\", \"person_home_ownership_2\", \"loan_percent_income\", \"person_age\", \"loan_intent_5\", \"loan_status\", \"loan_grade_2\", \"person_emp_length\", \"loan_intent_4\", \"loan_intent_1\", \"person_home_ownership_1\", \"cb_person_cred_hist_length\", \"person_income\", \"loan_int_rate\", \"loan_intent_2\", \"cb_person_default_on_file_1\", \"loan_grade_3\", \"loan_grade_1\"\n",
    "\n",
    "from aoa import ModelContext, DatasetInfo\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.expanduser(f\"{model_local_path}/model_modules\"))\n",
    "\n",
    "import training\n",
    "training.train(context=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f5f3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24K\n",
      "drwxr-xr-x 2 root root 6.0K Jul 11 22:56 __pycache__\n",
      "-rw-r--r-- 1 root root 5.7K Jul 11 22:52 evaluation.py\n",
      "-rw-r--r-- 1 root root   98 Jul 11 22:53 requirements.txt\n",
      "-rw-r--r-- 1 root root 3.2K Jul 11 22:52 scoring.py\n",
      "-rw-r--r-- 1 root root 3.3K Jul 11 22:56 training.py\n"
     ]
    }
   ],
   "source": [
    "# Check the generated files\n",
    "#!dir  model_modules\n",
    "!ls -lh model_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f052a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">4. Defina la función de evaluación</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">La función de evaluación tiene la siguiente estructura :</p>\n",
    "\n",
    "```python\n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model from Vantage\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_evaluation_stats(...)\n",
    "```\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Se puede crear desde CLI  o en el notebook como se muestra a continuación.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e017d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/evaluation.py \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform,\n",
    "    ClassificationEvaluator,\n",
    "    ConvertTo,\n",
    "    ROC\n",
    ")\n",
    "from aoa import (\n",
    "    record_evaluation_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind=\"barh\").set_title(\"Feature Importance\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix(cf, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(cf, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cf.shape[0]):\n",
    "        for j in range(cf.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cf[i, j], va=\"center\", ha=\"center\", size=\"xx-large\")\n",
    "    ax.set_xlabel(\"Predicted labels\");\n",
    "    ax.set_ylabel(\"True labels\"); \n",
    "    ax.set_title(\"Confusion Matrix\");\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_roc_curve(roc_out, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    auc = roc_out.result.to_pandas().reset_index()[\"AUC\"][0]\n",
    "    roc_results = roc_out.output_data.to_pandas()\n",
    "    plt.plot(roc_results[\"fpr\"], roc_results[\"tpr\"], color=\"darkorange\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % 0.27)\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    test_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    # Scaling the test set\n",
    "    #print (\"Loading scaler...\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_test = ScaleTransform(\n",
    "    #    data=test_df,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_test.result,\n",
    "        newdata=test_df,\n",
    "        accumulate=target_name,\n",
    "        id_column=entity_key,\n",
    "        output_prob=True,\n",
    "        output_responses=[\"0\",\"1\"]\n",
    "    )\n",
    "\n",
    "    predicted_data = ConvertTo(\n",
    "        data = predictions.result,\n",
    "        target_columns = [target_name,\"prediction\"],\n",
    "        target_datatype = [\"INTEGER\"]\n",
    "    )\n",
    "\n",
    "    ClassificationEvaluator_obj = ClassificationEvaluator(\n",
    "        data=predicted_data.result,\n",
    "        observation_column=target_name,\n",
    "        prediction_column=\"prediction\",\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "    metrics_pd = ClassificationEvaluator_obj.output_data.to_pandas()\n",
    "\n",
    "    evaluation = {\n",
    "        \"Accuracy\": \"{:.2f}\".format(metrics_pd.MetricValue[0]),\n",
    "        \"Micro-Precision\": \"{:.2f}\".format(metrics_pd.MetricValue[1]),\n",
    "        \"Micro-Recall\": \"{:.2f}\".format(metrics_pd.MetricValue[2]),\n",
    "        \"Micro-F1\": \"{:.2f}\".format(metrics_pd.MetricValue[3]),\n",
    "        \"Macro-Precision\": \"{:.2f}\".format(metrics_pd.MetricValue[4]),\n",
    "        \"Macro-Recall\": \"{:.2f}\".format(metrics_pd.MetricValue[5]),\n",
    "        \"Macro-F1\": \"{:.2f}\".format(metrics_pd.MetricValue[6]),\n",
    "        \"Weighted-Precision\": \"{:.2f}\".format(metrics_pd.MetricValue[7]),\n",
    "        \"Weighted-Recall\": \"{:.2f}\".format(metrics_pd.MetricValue[8]),\n",
    "        \"Weighted-F1\": \"{:.2f}\".format(metrics_pd.MetricValue[9]),\n",
    "    }\n",
    "\n",
    "    with open(f\"{context.artifact_output_path}/metrics.json\", \"w+\") as f:\n",
    "        json.dump(evaluation, f)\n",
    "        \n",
    "    cm = confusion_matrix(predicted_data.result.to_pandas()[\"loan_status\"], predicted_data.result.to_pandas()[\"prediction\"])\n",
    "    plot_confusion_matrix(cm, f\"{context.artifact_output_path}/confusion_matrix\")\n",
    "\n",
    "    #roc_out = ROC(\n",
    "    #    data=predictions.result,\n",
    "    #    probability_column=\"prob_1\",\n",
    "    #    observation_column=target_name,\n",
    "    #    positive_class=\"1\",\n",
    "    #    num_thresholds=1000\n",
    "    #)\n",
    "    #plot_roc_curve(roc_out, f\"{context.artifact_output_path}/roc_curve\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    model_pdf = model.to_pandas()[[\"predictor\",\"estimate\"]]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row[\"predictor\"] in feature_names:\n",
    "            value = row[\"estimate\"]\n",
    "            predictor_dict[row[\"predictor\"]] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    predictions_table = \"predictions_tmp\"\n",
    "    copy_to_sql(df=predicted_data.result, table_name=predictions_table, index=False, if_exists=\"replace\", temporary=True)\n",
    "\n",
    "    # calculate stats if training stats exist\n",
    "    if os.path.exists(f\"{context.artifact_input_path}/data_stats.json\"):\n",
    "        record_evaluation_stats(\n",
    "            features_df=test_df,\n",
    "            predicted_df=DataFrame.from_query(f\"SELECT * FROM {predictions_table}\"),\n",
    "            feature_importance=feature_importance,\n",
    "            context=context\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9e3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring\n",
      "{'Accuracy': '0.78', 'Micro-Precision': '0.78', 'Micro-Recall': '0.78', 'Micro-F1': '0.78', 'Macro-Precision': '0.66', 'Macro-Recall': '0.50', 'Macro-F1': '0.44', 'Weighted-Precision': '0.73', 'Weighted-Recall': '0.78', 'Weighted-F1': '0.69'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 750x750 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebok se define lo siguiente :\n",
    "\n",
    "# define the evaluation dataset \n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=2\n",
    "\"\"\"\n",
    "\n",
    "entity_key = \"id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    artifact_input_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "import evaluation\n",
    "evaluation.evaluate(context=ctx)\n",
    "\n",
    "# view evaluation results\n",
    "import json\n",
    "with open(f\"{ctx.artifact_output_path}/metrics.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd20501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 248K\n",
      "-rw-r--r-- 1 root root 126K Jul 11 22:56 confusion_matrix.png\n",
      "-rw-r--r-- 1 root root 2.5K Jul 11 22:56 data_stats.json\n",
      "-rw-r--r-- 1 root root 110K Jul 11 22:56 feature_importance.png\n",
      "-rw-r--r-- 1 root root  242 Jul 11 22:56 metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Check the generated files\n",
    "#!dir artifacts\n",
    "!ls -lh artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcdfc8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">5. Defina función de Scoring</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"><La función de scoring tiene la siguiente estructura : ></p>\n",
    "\n",
    "```python\n",
    "def score(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_scoring_stats(...)\n",
    "```\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Se puede ejecutar desde  CLI o desde  notebook de la siguiente forma.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f77825ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/scoring.py \n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_scoring_stats,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def score(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    features_tdf = DataFrame.from_query(context.dataset_info.sql)\n",
    "    features_pdf = features_tdf.to_pandas(all_rows=True)\n",
    "\n",
    "    # Scaling the scoring set\n",
    "    print (\"Loading scaler...NO\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_features = ScaleTransform(\n",
    "    #    data=features_tdf,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = entity_key\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_features.result,\n",
    "        newdata=features_tdf,\n",
    "        id_column=entity_key\n",
    "    )\n",
    "\n",
    "    predictions_pdf = predictions.result.to_pandas(all_rows=True).rename(columns={\"prediction\": target_name}).astype(int)\n",
    "\n",
    "    print(\"Finished Scoring\")\n",
    "\n",
    "    # store the predictions\n",
    "    predictions_pdf = pd.DataFrame(predictions_pdf, columns=[target_name])\n",
    "    predictions_pdf[entity_key] = features_pdf.index.values\n",
    "    # add job_id column so we know which execution this is from if appended to predictions table\n",
    "    predictions_pdf[\"job_id\"] = context.job_id\n",
    "\n",
    "    # teradataml doesn\"t match column names on append.. and so to match / use same table schema as for byom predict\n",
    "    # example (see README.md), we must add empty json_report column and change column order manually (v17.0.0.4)\n",
    "    # CREATE MULTISET TABLE pima_patient_predictions\n",
    "    # (\n",
    "    #     job_id VARCHAR(255), -- comes from airflow on job execution\n",
    "    #     PatientId BIGINT,    -- entity key as it is in the source data\n",
    "    #     HasDiabetes BIGINT,   -- if model automatically extracts target\n",
    "    #     json_report CLOB(1048544000) CHARACTER SET UNICODE  -- output of\n",
    "    # )\n",
    "    # PRIMARY INDEX ( job_id );\n",
    "    predictions_pdf[\"json_report\"] = \"\"\n",
    "    predictions_pdf = predictions_pdf[[\"job_id\", entity_key, target_name, \"json_report\"]]\n",
    "    print (context.dataset_info.predictions_database)\n",
    "    print(context.dataset_info.predictions_table)\n",
    "    copy_to_sql(\n",
    "        df=predictions_pdf,\n",
    "        schema_name=context.dataset_info.predictions_database,\n",
    "        table_name=context.dataset_info.predictions_table,\n",
    "        index=False,\n",
    "        if_exists=\"append\"\n",
    "    )\n",
    "    \n",
    "    print(\"Saved predictions in Teradata\")\n",
    "    print({context.dataset_info.get_predictions_metadata_fqtn()} )\n",
    "    print({context.job_id})\n",
    "    qry = f\"\"\"\n",
    "        SELECT \n",
    "            * \n",
    "        FROM {context.dataset_info.get_predictions_metadata_fqtn()} \n",
    "            WHERE job_id = \"{context.job_id}\"\n",
    "    \"\"\"\n",
    "    print(qry)\n",
    "    #calculate stats\n",
    "    predictions_df = DataFrame.from_query(f\"\"\"\n",
    "        SELECT \n",
    "            * \n",
    "        FROM {context.dataset_info.get_predictions_metadata_fqtn()} \n",
    "            WHERE job_id = '{context.job_id}'\n",
    "    \"\"\")\n",
    "\n",
    "    record_scoring_stats(features_df=features_tdf, predicted_df=predictions_df, context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04af97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scaler...NO\n",
      "Scoring\n",
      "Finished Scoring\n",
      "tdbacen\n",
      "CreditRisk_prediction\n",
      "Saved predictions in Teradata\n",
      "{'tdbacen.CreditRisk_prediction'}\n",
      "{'e71908ae-7b95-4fe7-8c4a-6348b4ab01cb'}\n",
      "\n",
      "        SELECT \n",
      "            * \n",
      "        FROM tdbacen.CreditRisk_prediction \n",
      "            WHERE job_id = \"e71908ae-7b95-4fe7-8c4a-6348b4ab01cb\"\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Se hace automatico por modelop via CLI / UI. sin embargo para probar el notebook, se puede definir lo siguiente\n",
    "\n",
    "# define the scoring dataset \n",
    "\n",
    "sql = \"\"\"\n",
    "      Select * from tdbacen.CreditRisk_dataset\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# where to store predictions\n",
    "predictions = {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"CreditRisk_prediction\"\n",
    "}\n",
    "\n",
    "import uuid\n",
    "job_id=str(uuid.uuid4())\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata,\n",
    "                           predictions=predictions)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"artifacts/\",\n",
    "                   artifact_input_path=\"artifacts/\",\n",
    "                   model_version=\"InDB_v1\",\n",
    "                   model_table=\"model_InDB_v1\",\n",
    "                   job_id=job_id)\n",
    "\n",
    "import scoring\n",
    "scoring.score(context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d57f577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>job_id</th>\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>loan_status</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>21595</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>9523</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>6036</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>31791</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>25755</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>17170</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>16497</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>4894</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>20657</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>e71908ae-7b95-4fe7-8c4a-6348b4ab01cb</td>\n",
       "\t\t<td>15090</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                     job_id  loan_status json_report\n",
       "id                                                                  \n",
       "21595  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "9523   e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "6036   e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "31791  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "25755  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "17170  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "16497  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "4894   e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "20657  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            \n",
       "15090  e71908ae-7b95-4fe7-8c4a-6348b4ab01cb            0            "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame.from_query(f\"SELECT * FROM tdbacen.CreditRisk_prediction WHERE job_id='{job_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "582e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (Lo dejo comentariado)\n",
    "#os.system(\"rm -f artifacts/*\")\n",
    "\n",
    "#try:\n",
    "#    db_drop_table(\"model_InDB_v1\")\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table(\"scaler_InDB_v1\")\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table(\"pima_patient_predictions_tmp\")\n",
    "#except: \n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d9a73",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">6. Define la metadata del modelo</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Ahora crear el archivo de configuración.<br>El archivo de dependencias con sus versiones:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f946e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/requirements.txt\n",
    "teradataml==17.20.0.6\n",
    "teradatamodelops==7.0.3\n",
    "pandas==2.1.4\n",
    "scikit-learn==1.3.2\n",
    "matplotlib==3.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af179c7",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Configure los hiper parametros (Valores x Defecto):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37165d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/config.json\n",
    "{\n",
    "   \"hyperParameters\": {\n",
    "        \"scale_method\":\"STD\",\n",
    "        \"miss_value\":\"KEEP\",\n",
    "        \"global_scale\": \"False\",\n",
    "        \"multiplier\":\"1\",\n",
    "        \"intercept\":\"0\",\n",
    "        \"family\": \"BINOMIAL\", \n",
    "        \"learning_rate\": \"OPTIMAL\",\n",
    "        \"momentum\": 0.80,\n",
    "        \"initial_eta\": 0.05,\n",
    "        \"local_sgd_iterations\": 10,\n",
    "        \"iter_max\": 100,\n",
    "        \"batch_size\": 50,\n",
    "        \"iter_num_no_change\": 5\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4467f",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">La configuración del modelo:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "236decde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model.json\n",
    "{\n",
    "    \"id\": \"f8df0bec-12d1-4d2d-920f-4448503df82d\",\n",
    "    \"name\": \"Modelo Riesgos\" ,\n",
    "    \"description\": \"Riesgos de creditos\",\n",
    "    \"language\": \"python\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b17a7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">7. Commit and Push to Git to let ModelOps manage</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Run the command below to commit and push changes to our forked repository, so ModelOps can fetch the changes to the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45c4ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Unable to create '/home/demouser/JT250043/modelops/.git/index.lock': File exists.\n",
      "\n",
      "Another git process seems to be running in this repository, e.g.\n",
      "an editor opened by 'git commit'. Please make sure all processes\n",
      "are terminated then try again. If it still fails, a git process\n",
      "may have crashed in this repository earlier:\n",
      "remove the file manually to continue.\n"
     ]
    }
   ],
   "source": [
    "!cd $model_local_path/../.. && git add . && git commit -m \"Added Python PIMA InDB GLM demo model 🚀\" && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7cf2a",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Now that changes are pushed, you can make the lifecycle inside <b>ModelOps User Interface</b>, plan for new trainings, evaluations and scorings. Compare models and operationalize into Production with automated Monitoring and alerting capabilities.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a160f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">8. ModelOps full lifecycle till deployment</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88476c06-359f-41ea-b65e-67327de32ed7",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1554f-4c37-4a3a-a333-a96a505dafdf",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046954d-65b1-4939-9ff9-2e12411f3e7e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">10. Cleanup</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b210b57-bbc3-485b-a6cc-fbd01f06253f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">If you are done with ModelOps usecase, please uncomment and run the below cleanup section.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bcd8c6-7d73-46e3-8a22-f81c30119256",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>Work Tables</b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e49a6-3cd3-49cd-9cfa-c0342c9d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_drop_table(table_name = \"aoa_byom_models\", schema_name = \"demo_user\")\n",
    "# db_drop_table(table_name = \"pima_patient_predictions\", schema_name = \"demo_user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd8630-f040-4583-af23-d0a30f8901ed",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"> <b>Databases and Tables </b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbc041-b2d5-4926-bae2-0b1cee3d3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../UseCases/run_procedure.py \"call remove_data(\"DEMO_ModelOps\");\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f8688-e4e8-46b8-9bba-2c88d9eefe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d459036-095d-4dc9-a082-1575ada88fa9",
   "metadata": {},
   "source": [
    "[<< Back to GIT Project Setup](./06_ModelOps_GIT_Project_Setup.ipynb) | [Continue to GIT PIMA H2OAutoML >>](./08_ModelOps_GIT_PIMA_Python_H2OAutoML.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b9f6a-8ac5-4890-9b54-1afd8e9c93e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
