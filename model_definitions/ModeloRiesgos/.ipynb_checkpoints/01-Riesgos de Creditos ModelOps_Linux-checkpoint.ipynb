{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e00e6e",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style=\"font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;\">\n",
    "       ModelOps demo - Python In-database Using Git\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a96f35c",
   "metadata": {},
   "source": [
    "<p style = \"font-size:20px;font-family:Arial;color:#00233C\"><b>Introducción</b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">\n",
    "Este es un modelo de prueba.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bb3df",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>Pasos dentro del Notebook</b></p>\n",
    "<ol style = \"font-size:16px;font-family:Arial;color:#00233C\">\n",
    "<li>Configure el ambiente </li>\n",
    " <li>Conectarse a Vantage</li>\n",
    " <li>Defina la función training</li>\n",
    " <li>Defina la función evaluation</li>\n",
    " <li>Defina la funcion de Scoring</li>\n",
    " <li>Defina la metadata del modelo</li>\n",
    " <li>CHaga commit y push en el Git del modelo</li>\n",
    " <li>Ciclo completo de desarrollot</li>\n",
    " <li>Monitoreo</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9eaa38",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">1. Configure el ambiente</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Instalar e Importar las librerias requeridas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7606f8",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>1.1 Instalación de librerias</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"><b>Es importante reininicar el kerner para confirmar el uso de las librerias</b>. Se usa el parametro -q  para evitar el log de la instalacion de las librerias..</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471a044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q teradataml==17.20.0.6 teradatamodelops==7.0.3 matplotlib==3.8.2\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210b4c9-7d3d-4daa-9ada-28f2591351ae",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"><b>Hint:</b><i>The easy way to restart the kernel to bring the above installed software into memory is to type zero zero (<b> 0 0 </b>). </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ef23e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>1.2 Importar Librerias</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cb09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b744bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "import os\n",
    "import getpass\n",
    "import logging\n",
    "import sys\n",
    "##########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf237b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">2. Conectar a Vantage</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80378f0d-a464-40bf-9180-03da16c0e96c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(teradatasql://tdbacen:***@40.71.87.158)\n"
     ]
    }
   ],
   "source": [
    "#%run -i ../UseCases/startup.ipynb\n",
    "eng = create_context(host = \"40.71.87.158\", username=\"tdbacen\", password = \"tdbacen\")\n",
    "\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab4684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81eaf79-ccd8-421d-9a75-046607a69a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "execute_sql('''SET query_band='DEMO=Ejemplo para crear proyecto ModelOps;' UPDATE FOR SESSION; ''')\n",
    "\n",
    "# configure byom/val \n",
    "configure.val_install_location = \"VAL\"\n",
    "configure.byom_install_location = \"MLDB\"\n",
    "\n",
    "# Configure el PATH al repositorio local\n",
    "\n",
    "#model_local_path = \".\"\n",
    "model_local_path = os.getcwd() \n",
    "res1 = os.system(f\"mkdir -p {model_local_path}/artifacts\")  # Para Unix usar el -p y /\n",
    "res = os.system(f\"mkdir -p {model_local_path}/model_modules\")  # Para Unix usar el -p y /\n",
    "\n",
    "#res1 = os.system(f\"mkdir  {model_local_path}\\\\artifacts\")\n",
    "#res = os.system(f\"mkdir  {model_local_path}\\\\model_modules\") # Para Windows quitar el -p y usar \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276b9aa-0bb5-461f-b4e1-e6ef4afd3e97",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>Crear la tabla</b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"> Se crea la tabla para almacenar el modelo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a5acfa-9dbd-4e7b-bc5c-1a9f115ca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Aoa_Byom_Models \n",
    "query = \"\"\"CREATE SET TABLE Aoa_Byom_Models \n",
    "     (\n",
    "      model_version VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      model_type VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      project_id VARCHAR(255) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      deployed_at TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),\n",
    "      model BLOB(2097088000))\n",
    "UNIQUE PRIMARY INDEX ( model_version );\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table(\"Aoa_Byom_Models\")\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba6a4f",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"> Se crea la tabla para almacenar las predicciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0223483a-5f1b-430d-87f3-db0a8ab2466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddl for Pima_Patient_Predictions\n",
    "query = \"\"\"CREATE MULTISET TABLE tdbacen.CreditRisk_prediction  ,FALLBACK ,\n",
    "    NO BEFORE JOURNAL,\n",
    "    NO AFTER JOURNAL,\n",
    "    CHECKSUM = DEFAULT,\n",
    "    DEFAULT MERGEBLOCKRATIO,\n",
    "    MAP = TD_MAP1\n",
    "    (\n",
    "        job_id VARCHAR(1024) ,\n",
    "        id BIGINT,\n",
    "        loan_status INTEGER,\n",
    "         json_report VARCHAR(1024) \n",
    "    )\n",
    "    PRIMARY INDEX ( id );;\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table(\"CreditRisk_prediction\")\n",
    "    execute_sql(query) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec57466",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">3. Defina la función Training</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">La funcion training tiene la siguiente estructura </p>\n",
    "\n",
    "```python\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "    \n",
    "    # Su codigo de entrenamiento usando  funciones teradataml \n",
    "    model = <InDB Function>(...)\n",
    "    \n",
    "    # Guarde el modelo\n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")  \n",
    "    \n",
    "    record_training_stats(...)\n",
    "```\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Se puede ejecutar desde CLI o directamente dentro del notebook.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fc1b7-011c-4202-b2c7-97b78f8da2c3",
   "metadata": {},
   "source": [
    "!echo $model_local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563ae03-75c9-4434-ade0-b7d84bcc31fd",
   "metadata": {},
   "source": [
    "La siguente celda en Windows cambia por = %%wwritefile $model_local_path\\model_modules\\training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51bb236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/training.py \n",
    "from teradataml import (\n",
    "    DataFrame,\n",
    "    GLM,\n",
    "    ScaleFit,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_training_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind=\"barh\").set_title(\"Feature Importance\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def train(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    # read training dataset from Teradata and convert to pandas\n",
    "    train_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    print (\"Scaling using InDB Functions... Rev 1234567\")\n",
    "    \n",
    "    #scaler = ScaleFit(\n",
    "    #    data=train_df,\n",
    "    #    target_columns = feature_names,\n",
    "    #    scale_method = context.hyperparams[\"scale_method\"],\n",
    "    #    miss_value = context.hyperparams[\"miss_value\"],\n",
    "    #    global_scale = context.hyperparams[\"global_scale\"].lower() in [\"true\", \"1\"],\n",
    "    #    multiplier = context.hyperparams[\"multiplier\"],\n",
    "    #    intercept = context.hyperparams[\"intercept\"]\n",
    "    #)\n",
    "\n",
    "\n",
    "    #scaled_train = ScaleTransform(\n",
    "    #    data=train_df,\n",
    "    #    object=scaler.output,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "  #  scaler.output.to_sql(f\"scaler_${context.model_version}\", if_exists=\"replace\")\n",
    "  #  print(\"Saved scaler\")\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    \n",
    "    model = GLM(input_columns= feature_names,\n",
    "                 response_column = target_name,\n",
    "                #data = scaled_train.result, \n",
    "                data = train_df, \n",
    "                family = context.hyperparams[\"family\"],\n",
    "                iter_max = context.hyperparams[\"iter_max\"],\n",
    "               learning_rate = context.hyperparams[\"learning_rate\"],\n",
    "                momentum = context.hyperparams[\"momentum\"]\n",
    "               )\n",
    "    \n",
    "    model.result.to_sql(f\"model_${context.model_version}\", if_exists=\"replace\")    \n",
    "    print(\"Saved trained model xyz\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    \n",
    "    model_pdf = model.result.to_pandas()[['predictor','estimate']]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row['predictor'] in feature_names:\n",
    "            value = row['estimate']\n",
    "            predictor_dict[row['predictor']] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    print(feature_names)\n",
    "    print(target_name)\n",
    "    print(feature_importance)\n",
    "    print(context)\n",
    "    \n",
    "    #record_training_stats(\n",
    "    #    train_df,\n",
    "    #    features=feature_names,\n",
    "    #    targets=[target_name],\n",
    "    #    categorical=[target_name],\n",
    "    #    feature_importance=feature_importance,\n",
    "    #    context=context\n",
    "    #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aa3c146-c31c-4bfb-b74c-8f1476714987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b1483fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling using InDB Functions... Rev 1234567\n",
      "Starting training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[Teradata][teradataml](TDML_2051) Column 'cb_person_default_on_file_other' provided in 'input_columns' argument, does not exist in 'data' DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_local_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_modules\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraining\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/training.py:61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(context, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[38;5;66;03m#scaler = ScaleFit(\u001b[39;00m\n\u001b[1;32m     39\u001b[0m   \u001b[38;5;66;03m#    data=train_df,\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;66;03m#    target_columns = feature_names,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#  scaler.output.to_sql(f\"scaler_${context.model_version}\", if_exists=\"replace\")\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#  print(\"Saved scaler\")\u001b[39;00m\n\u001b[1;32m     58\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mGLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m               \u001b[49m\u001b[43mresponse_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;66;43;03m#data = scaled_train.result, \u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfamily\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m              \u001b[49m\u001b[43miter_max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miter_max\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m             \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m   model\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_$\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;241m.\u001b[39mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved trained model xyz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/sqle/__init__.py:97\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m assoc_cl \u001b[38;5;129;01min\u001b[39;00m _get_associated_parent_classes(func):\n\u001b[1;32m     96\u001b[0m     _c \u001b[38;5;241m=\u001b[39m _c \u001b[38;5;241m+\u001b[39m (assoc_cl, )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[func] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(func), _c, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43m_common_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msqle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__doc__\u001b[39m\u001b[38;5;124m\"\u001b[39m: _AnalyticFunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m})\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/meta_class.py:188\u001b[0m, in \u001b[0;36m_common_init\u001b[0;34m(self, function_type, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqle\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mteradataml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytic_function_executor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SQLEFunctionExecutor\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43m_SQLEFunctionExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muaf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mteradataml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytic_function_executor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _UAFFunctionExecutor\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/analytic_function_executor.py:717\u001b[0m, in \u001b[0;36m_AnlyticFunctionExecutor._execute_function\u001b[0;34m(self, skip_input_arg_processing, skip_output_arg_processing, skip_other_arg_processing, skip_func_output_processing, skip_dyn_cls_processing, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_output_argument(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_other_arg_processing:\n\u001b[0;32m--> 717\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_other_argument\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_query(volatile\u001b[38;5;241m=\u001b[39mvolatile)\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# Print SQL-MR query if requested to do so.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/analytic_function_executor.py:459\u001b[0m, in \u001b[0;36m_AnlyticFunctionExecutor._process_other_argument\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39m_mlresults[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Validate column is existed or not in the table.\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m \u001b[43m_Validators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dataframe_has_argument_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_table_argument_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# Append square brackets for column range when function\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# does not require special case handler.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m arg_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spl_func_obj\u001b[38;5;241m.\u001b[39m_add_square_bracket(arg_value)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:33\u001b[0m, in \u001b[0;36mskip_validation.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# If \"skip_all\" flag is set to False,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# skip all validation execution.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Validators\u001b[38;5;241m.\u001b[39mskip_all:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:381\u001b[0m, in \u001b[0;36m_Validators._validate_dataframe_has_argument_columns\u001b[0;34m(columns, column_arg, data, data_arg, is_partition_arg)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m             total_columns\u001b[38;5;241m.\u001b[39mappend(column)\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_Validators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_exists_in_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metaexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mdata_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_arg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:33\u001b[0m, in \u001b[0;36mskip_validation.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# If \"skip_all\" flag is set to False,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# skip all validation execution.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Validators\u001b[38;5;241m.\u001b[39mskip_all:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:467\u001b[0m, in \u001b[0;36m_Validators._validate_column_exists_in_dataframe\u001b[0;34m(columns, metaexpr, case_insensitive, column_arg, data_arg, for_table)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m column_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m unquoted_df_columns:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_arg \u001b[38;5;129;01mand\u001b[39;00m data_arg:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Messages\u001b[38;5;241m.\u001b[39mget_message(MessageCodes\u001b[38;5;241m.\u001b[39mTDMLDF_COLUMN_IN_ARG_NOT_FOUND,\n\u001b[1;32m    468\u001b[0m                                               column_name,\n\u001b[1;32m    469\u001b[0m                                               column_arg,\n\u001b[1;32m    470\u001b[0m                                               data_arg,\n\u001b[1;32m    471\u001b[0m                                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m for_table \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Messages\u001b[38;5;241m.\u001b[39mget_message(MessageCodes\u001b[38;5;241m.\u001b[39mTDMLDF_DROP_INVALID_COL,\n\u001b[1;32m    474\u001b[0m                                               column_name, \u001b[38;5;28msorted\u001b[39m(unquoted_df_columns)))\n",
      "\u001b[0;31mValueError\u001b[0m: [Teradata][teradataml](TDML_2051) Column 'cb_person_default_on_file_other' provided in 'input_columns' argument, does not exist in 'data' DataFrame."
     ]
    }
   ],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebook se define lo siguiente :\n",
    "\n",
    "# define the training dataset \n",
    "#sql = \"\"\"\n",
    "#SELECT \n",
    "#    F.*, D.hasdiabetes\n",
    "#FROM tdbacen.PIMA_PATIENT_FEATURES F \n",
    "#JOIN tdbacen.PIMA_PATIENT_DIAGNOSES D\n",
    "#ON F.patientid = D.patientid\n",
    "#    WHERE D.patientid MOD 5 <> 0\n",
    "#\"\"\"\n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=1 \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "feature_metadata =  {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"riesgos_statistics_metadata\"\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"family\": \"BINOMIAL\", \n",
    "    \"learning_rate\": \"OPTIMAL\",\n",
    "    \"momentum\": 0.6,\n",
    "    \"iter_max\": 100,\n",
    "    \n",
    "    \"scale_method\":\"STD\",\n",
    "    \"miss_value\":\"KEEP\",\n",
    "    \"global_scale\":\"False\",\n",
    "    \"multiplier\":\"1\",\n",
    "    \"intercept\":\"0\",\n",
    "    \"initial_eta\": 0.05,\n",
    "    \"local_sgd_iterations\": 10,\n",
    "    \"batch_size\": 50,\n",
    "    \"iter_num_no_change\": 5\n",
    "}\n",
    "\n",
    "entity_key = \"Id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "#target_names = [\"loan_status\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "#feature_names = [\"person_income\",\"loan_amnt\"]\n",
    "#, \"loan_intent_3\", \"loan_grade_5\", \"cb_person_default_on_file_0\", \"loan_grade_4\", \"person_home_ownership_3\", \"loan_amnt\", \"loan_intent_0\", \"person_home_ownership_0\", \"loan_grade_6\", \"person_home_ownership_2\", \"loan_percent_income\", \"person_age\", \"loan_intent_5\", \"loan_status\", \"loan_grade_2\", \"person_emp_length\", \"loan_intent_4\", \"loan_intent_1\", \"person_home_ownership_1\", \"cb_person_cred_hist_length\", \"person_income\", \"loan_int_rate\", \"loan_intent_2\", \"cb_person_default_on_file_1\", \"loan_grade_3\", \"loan_grade_1\"\n",
    "\n",
    "from aoa import ModelContext, DatasetInfo\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.expanduser(f\"{model_local_path}/model_modules\"))\n",
    "\n",
    "import training\n",
    "training.train(context=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated files\n",
    "#!dir  model_modules\n",
    "!ls -lh model_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f052a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">4. Defina la función de evaluación</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">La función de evaluación tiene la siguiente estructura :</p>\n",
    "\n",
    "```python\n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model from Vantage\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_evaluation_stats(...)\n",
    "```\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Se puede crear desde CLI  o en el notebook como se muestra a continuación.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e017d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $model_local_path/model_modules/evaluation.py \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform,\n",
    "    ClassificationEvaluator,\n",
    "    ConvertTo,\n",
    "    ROC\n",
    ")\n",
    "from aoa import (\n",
    "    record_evaluation_stats,\n",
    "    save_plot,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_feature_importance(fi, img_filename):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    feat_importances = pd.Series(fi)\n",
    "    feat_importances.nlargest(10).plot(kind=\"barh\").set_title(\"Feature Importance\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix(cf, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    ax.matshow(cf, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cf.shape[0]):\n",
    "        for j in range(cf.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cf[i, j], va=\"center\", ha=\"center\", size=\"xx-large\")\n",
    "    ax.set_xlabel(\"Predicted labels\");\n",
    "    ax.set_ylabel(\"True labels\"); \n",
    "    ax.set_title(\"Confusion Matrix\");\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_roc_curve(roc_out, img_filename):\n",
    "    import matplotlib.pyplot as plt\n",
    "    auc = roc_out.result.to_pandas().reset_index()[\"AUC\"][0]\n",
    "    roc_results = roc_out.output_data.to_pandas()\n",
    "    plt.plot(roc_results[\"fpr\"], roc_results[\"tpr\"], color=\"darkorange\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % 0.27)\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(img_filename, dpi=500)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def evaluate(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    test_df = DataFrame.from_query(context.dataset_info.sql)\n",
    "\n",
    "    # Scaling the test set\n",
    "    #print (\"Loading scaler...\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_test = ScaleTransform(\n",
    "    #    data=test_df,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = [target_name,entity_key]\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_test.result,\n",
    "        newdata=test_df,\n",
    "        accumulate=target_name,\n",
    "        id_column=entity_key,\n",
    "        output_prob=True,\n",
    "        output_responses=[\"0\",\"1\"]\n",
    "    )\n",
    "\n",
    "    predicted_data = ConvertTo(\n",
    "        data = predictions.result,\n",
    "        target_columns = [target_name,\"prediction\"],\n",
    "        target_datatype = [\"INTEGER\"]\n",
    "    )\n",
    "\n",
    "    ClassificationEvaluator_obj = ClassificationEvaluator(\n",
    "        data=predicted_data.result,\n",
    "        observation_column=target_name,\n",
    "        prediction_column=\"prediction\",\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "    metrics_pd = ClassificationEvaluator_obj.output_data.to_pandas()\n",
    "\n",
    "    evaluation = {\n",
    "        \"Accuracy\": \"{:.2f}\".format(metrics_pd.MetricValue[0]),\n",
    "        \"Micro-Precision\": \"{:.2f}\".format(metrics_pd.MetricValue[1]),\n",
    "        \"Micro-Recall\": \"{:.2f}\".format(metrics_pd.MetricValue[2]),\n",
    "        \"Micro-F1\": \"{:.2f}\".format(metrics_pd.MetricValue[3]),\n",
    "        \"Macro-Precision\": \"{:.2f}\".format(metrics_pd.MetricValue[4]),\n",
    "        \"Macro-Recall\": \"{:.2f}\".format(metrics_pd.MetricValue[5]),\n",
    "        \"Macro-F1\": \"{:.2f}\".format(metrics_pd.MetricValue[6]),\n",
    "        \"Weighted-Precision\": \"{:.2f}\".format(metrics_pd.MetricValue[7]),\n",
    "        \"Weighted-Recall\": \"{:.2f}\".format(metrics_pd.MetricValue[8]),\n",
    "        \"Weighted-F1\": \"{:.2f}\".format(metrics_pd.MetricValue[9]),\n",
    "    }\n",
    "\n",
    "    with open(f\"{context.artifact_output_path}/metrics.json\", \"w+\") as f:\n",
    "        json.dump(evaluation, f)\n",
    "        \n",
    "    cm = confusion_matrix(predicted_data.result.to_pandas()[\"loan_status\"], predicted_data.result.to_pandas()[\"prediction\"])\n",
    "    plot_confusion_matrix(cm, f\"{context.artifact_output_path}/confusion_matrix\")\n",
    "\n",
    "    #roc_out = ROC(\n",
    "    #    data=predictions.result,\n",
    "    #    probability_column=\"prob_1\",\n",
    "    #    observation_column=target_name,\n",
    "    #    positive_class=\"1\",\n",
    "    #    num_thresholds=1000\n",
    "    #)\n",
    "    #plot_roc_curve(roc_out, f\"{context.artifact_output_path}/roc_curve\")\n",
    "\n",
    "    # Calculate feature importance and generate plot\n",
    "    model_pdf = model.to_pandas()[[\"predictor\",\"estimate\"]]\n",
    "    predictor_dict = {}\n",
    "    \n",
    "    for index, row in model_pdf.iterrows():\n",
    "        if row[\"predictor\"] in feature_names:\n",
    "            value = row[\"estimate\"]\n",
    "            predictor_dict[row[\"predictor\"]] = value\n",
    "    \n",
    "    feature_importance = dict(sorted(predictor_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    keys, values = zip(*feature_importance.items())\n",
    "    norm_values = (values-np.min(values))/(np.max(values)-np.min(values))\n",
    "    feature_importance = {keys[i]: float(norm_values[i]*1000) for i in range(len(keys))}\n",
    "    plot_feature_importance(feature_importance, f\"{context.artifact_output_path}/feature_importance\")\n",
    "\n",
    "    predictions_table = \"predictions_tmp\"\n",
    "    copy_to_sql(df=predicted_data.result, table_name=predictions_table, index=False, if_exists=\"replace\", temporary=True)\n",
    "\n",
    "    # calculate stats if training stats exist\n",
    "    if os.path.exists(f\"{context.artifact_input_path}/data_stats.json\"):\n",
    "        record_evaluation_stats(\n",
    "            features_df=test_df,\n",
    "            predicted_df=DataFrame.from_query(f\"SELECT * FROM {predictions_table}\"),\n",
    "            feature_importance=feature_importance,\n",
    "            context=context\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el contexto para probar. El contexto del modelo es creado y administrado automaticamente por ModelOps  \n",
    "# cuando este ejecuta desde CLI/UI  sin embargo para probarlo en el Notebok se define lo siguiente :\n",
    "\n",
    "# define the evaluation dataset \n",
    "sql = \"\"\"\n",
    "    Select * from \n",
    "    (\n",
    "\t     SELECT a.* , SAMPLEID as sid\n",
    "\t     FROM (Select * from tdbacen.CreditRisk_dataset ) a\n",
    "\t     SAMPLE RANDOMIZED ALLOCATION 0.3, 0.3, 0.4\n",
    "\t ) b\n",
    "     Where b.Sid=2\n",
    "\"\"\"\n",
    "\n",
    "entity_key = \"id\"\n",
    "target_names = [\"loan_status\",\"prob_1\"]\n",
    "feature_names = [\"cb_person_default_on_file_0\", \"cb_person_default_on_file_1\", \"cb_person_default_on_file_other\", \"loan_grade_0\", \"loan_grade_1\", \"loan_grade_2\", \"loan_grade_3\", \"loan_grade_4\",\"loan_grade_5\", \"loan_grade_6\", \"loan_grade_other\", \"loan_intent_0\", \"loan_intent_1\", \"loan_intent_2\", \"loan_intent_3\", \"loan_intent_4\", \"loan_intent_5\", \"loan_intent_other\", \"person_home_ownership_0\", \"person_home_ownership_1\", \"person_home_ownership_2\", \"person_home_ownership_3\", \"person_home_ownership_other\", \"cb_person_cred_hist_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"person_age\", \"person_emp_length\", \"person_income\"]\n",
    "\n",
    "dataset_info = DatasetInfo(\n",
    "    sql=sql,\n",
    "    entity_key=entity_key,\n",
    "    feature_names=feature_names,\n",
    "    target_names=target_names,\n",
    "    feature_metadata=feature_metadata\n",
    ")\n",
    "\n",
    "ctx = ModelContext(\n",
    "    hyperparams=hyperparams,\n",
    "    dataset_info=dataset_info,\n",
    "    artifact_output_path=\"artifacts/\",\n",
    "    artifact_input_path=\"artifacts/\",\n",
    "    model_version=\"InDB_v1\",\n",
    "    model_table=\"model_InDB_v1\"\n",
    ")\n",
    "\n",
    "import evaluation\n",
    "evaluation.evaluate(context=ctx)\n",
    "\n",
    "# view evaluation results\n",
    "import json\n",
    "with open(f\"{ctx.artifact_output_path}/metrics.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd20501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated files\n",
    "#!dir artifacts\n",
    "!ls -lh artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcdfc8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">5. Defina función de Scoring</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\"><La función de scoring tiene la siguiente estructura : ></p>\n",
    "\n",
    "```python\n",
    "def score(context: ModelContext, **kwargs):\n",
    "    aoa_create_context()\n",
    "\n",
    "    # read your model\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "    \n",
    "    # your evaluation logic\n",
    "    \n",
    "    record_scoring_stats(...)\n",
    "```\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Se puede ejecutar desde  CLI o desde  notebook de la siguiente forma.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77825ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/scoring.py \n",
    "from teradataml import (\n",
    "    copy_to_sql,\n",
    "    DataFrame,\n",
    "    TDGLMPredict,\n",
    "    ScaleTransform\n",
    ")\n",
    "from aoa import (\n",
    "    record_scoring_stats,\n",
    "    aoa_create_context,\n",
    "    ModelContext\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def score(context: ModelContext, **kwargs):\n",
    "\n",
    "    aoa_create_context()\n",
    "\n",
    "    model = DataFrame(f\"model_${context.model_version}\")\n",
    "\n",
    "    feature_names = context.dataset_info.feature_names\n",
    "    target_name = context.dataset_info.target_names[0]\n",
    "    entity_key = context.dataset_info.entity_key\n",
    "\n",
    "    features_tdf = DataFrame.from_query(context.dataset_info.sql)\n",
    "    features_pdf = features_tdf.to_pandas(all_rows=True)\n",
    "\n",
    "    # Scaling the scoring set\n",
    "    print (\"Loading scaler...NO\")\n",
    "    #scaler = DataFrame(f\"scaler_${context.model_version}\")\n",
    "\n",
    "    #scaled_features = ScaleTransform(\n",
    "    #    data=features_tdf,\n",
    "    #    object=scaler,\n",
    "    #    accumulate = entity_key\n",
    "    #)\n",
    "    \n",
    "    print(\"Scoring\")\n",
    "    predictions = TDGLMPredict(\n",
    "        object=model,\n",
    "        #newdata=scaled_features.result,\n",
    "        newdata=features_tdf,\n",
    "        id_column=entity_key,\n",
    "        output_prob=True, \n",
    "        output_responses='1'\n",
    "    )\n",
    "\n",
    "    predictions_pdf = predictions.result.to_pandas(all_rows=True).rename(columns={\"prediction\": target_name}).astype(int)\n",
    "\n",
    "    print(\"Finished Scoring\")\n",
    "\n",
    "    # store the predictions\n",
    "    \n",
    "    predictions_pdf = pd.DataFrame(predictions_pdf, columns=[target_name])\n",
    "    predictions_pdf[entity_key] = features_pdf.index.values\n",
    "    \n",
    "    # add job_id column so we know which execution this is from if appended to predictions table\n",
    "    predictions_pdf[\"job_id\"] = context.job_id\n",
    "\n",
    "    # teradataml doesn\"t match column names on append.. and so to match / use same table schema as for byom predict\n",
    "    # example (see README.md), we must add empty json_report column and change column order manually (v17.0.0.4)\n",
    "    # CREATE MULTISET TABLE pima_patient_predictions\n",
    "    # (\n",
    "    #     job_id VARCHAR(255), -- comes from airflow on job execution\n",
    "    #     PatientId BIGINT,    -- entity key as it is in the source data\n",
    "    #     HasDiabetes BIGINT,   -- if model automatically extracts target\n",
    "    #     json_report CLOB(1048544000) CHARACTER SET UNICODE  -- output of\n",
    "    # )\n",
    "    # PRIMARY INDEX ( job_id );\n",
    "    \n",
    "    predictions_pdf[\"json_report\"] = \"\"\n",
    "    predictions_pdf = predictions_pdf[[\"job_id\", entity_key, target_name, \"json_report\"]]\n",
    "    \n",
    "    print (context.dataset_info.predictions_database)\n",
    "    print(context.dataset_info.predictions_table)\n",
    "    \n",
    "    \n",
    "    \n",
    "    copy_to_sql(df=predictions_pdf,\n",
    "                schema_name=context.dataset_info.predictions_database,\n",
    "                table_name=context.dataset_info.predictions_table,\n",
    "                index=False,\n",
    "                if_exists=\"append\")\n",
    "    \n",
    "    \n",
    "    print(\"Saved predictions in Teradata\")\n",
    "\n",
    "\n",
    "    #calculate stats\n",
    "    #predictions_df = DataFrame.from_query(f\"\"\"\n",
    "    #    SELECT \n",
    "    #        * \n",
    "    #    FROM {context.dataset_info.get_predictions_metadata_fqtn()} \n",
    "    #        WHERE job_id = '{context.job_id}'\n",
    "    #\"\"\")\n",
    "\n",
    "    #record_scoring_stats(features_df=features_tdf, predicted_df=predictions_df, context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d04af97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scaler...NO\n",
      "Scoring\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[Teradata][teradataml](TDML_2051) Column 'Id' provided in 'id_column' argument, does not exist in 'newdata' DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m ctx \u001b[38;5;241m=\u001b[39m ModelContext(hyperparams\u001b[38;5;241m=\u001b[39mhyperparams,\n\u001b[1;32m     27\u001b[0m                    dataset_info\u001b[38;5;241m=\u001b[39mdataset_info,\n\u001b[1;32m     28\u001b[0m                    artifact_output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m                    model_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_InDB_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m                    job_id\u001b[38;5;241m=\u001b[39mjob_id)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscoring\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mscoring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/scoring.py:39\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(context, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#scaler = DataFrame(f\"scaler_${context.model_version}\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#scaled_features = ScaleTransform(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#    accumulate = entity_key\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScoring\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mTDGLMPredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#newdata=scaled_features.result,\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_tdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentity_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_responses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m predictions_pdf \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mto_pandas(all_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: target_name})\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished Scoring\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/sqle/__init__.py:97\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m assoc_cl \u001b[38;5;129;01min\u001b[39;00m _get_associated_parent_classes(func):\n\u001b[1;32m     96\u001b[0m     _c \u001b[38;5;241m=\u001b[39m _c \u001b[38;5;241m+\u001b[39m (assoc_cl, )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[func] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(func), _c, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43m_common_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msqle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__doc__\u001b[39m\u001b[38;5;124m\"\u001b[39m: _AnalyticFunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m})\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/meta_class.py:188\u001b[0m, in \u001b[0;36m_common_init\u001b[0;34m(self, function_type, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqle\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mteradataml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytic_function_executor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SQLEFunctionExecutor\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43m_SQLEFunctionExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muaf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mteradataml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytic_function_executor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _UAFFunctionExecutor\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/analytic_function_executor.py:717\u001b[0m, in \u001b[0;36m_AnlyticFunctionExecutor._execute_function\u001b[0;34m(self, skip_input_arg_processing, skip_output_arg_processing, skip_other_arg_processing, skip_func_output_processing, skip_dyn_cls_processing, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_output_argument(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_other_arg_processing:\n\u001b[0;32m--> 717\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_other_argument\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_query(volatile\u001b[38;5;241m=\u001b[39mvolatile)\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# Print SQL-MR query if requested to do so.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/analytics/analytic_function_executor.py:459\u001b[0m, in \u001b[0;36m_AnlyticFunctionExecutor._process_other_argument\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39m_mlresults[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Validate column is existed or not in the table.\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m \u001b[43m_Validators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dataframe_has_argument_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_table_argument_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# Append square brackets for column range when function\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# does not require special case handler.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m arg_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spl_func_obj\u001b[38;5;241m.\u001b[39m_add_square_bracket(arg_value)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:33\u001b[0m, in \u001b[0;36mskip_validation.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# If \"skip_all\" flag is set to False,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# skip all validation execution.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Validators\u001b[38;5;241m.\u001b[39mskip_all:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:381\u001b[0m, in \u001b[0;36m_Validators._validate_dataframe_has_argument_columns\u001b[0;34m(columns, column_arg, data, data_arg, is_partition_arg)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m             total_columns\u001b[38;5;241m.\u001b[39mappend(column)\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_Validators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_exists_in_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metaexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mdata_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_arg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:33\u001b[0m, in \u001b[0;36mskip_validation.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# If \"skip_all\" flag is set to False,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# skip all validation execution.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Validators\u001b[38;5;241m.\u001b[39mskip_all:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/teradataml/utils/validators.py:467\u001b[0m, in \u001b[0;36m_Validators._validate_column_exists_in_dataframe\u001b[0;34m(columns, metaexpr, case_insensitive, column_arg, data_arg, for_table)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m column_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m unquoted_df_columns:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_arg \u001b[38;5;129;01mand\u001b[39;00m data_arg:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Messages\u001b[38;5;241m.\u001b[39mget_message(MessageCodes\u001b[38;5;241m.\u001b[39mTDMLDF_COLUMN_IN_ARG_NOT_FOUND,\n\u001b[1;32m    468\u001b[0m                                               column_name,\n\u001b[1;32m    469\u001b[0m                                               column_arg,\n\u001b[1;32m    470\u001b[0m                                               data_arg,\n\u001b[1;32m    471\u001b[0m                                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m for_table \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Messages\u001b[38;5;241m.\u001b[39mget_message(MessageCodes\u001b[38;5;241m.\u001b[39mTDMLDF_DROP_INVALID_COL,\n\u001b[1;32m    474\u001b[0m                                               column_name, \u001b[38;5;28msorted\u001b[39m(unquoted_df_columns)))\n",
      "\u001b[0;31mValueError\u001b[0m: [Teradata][teradataml](TDML_2051) Column 'Id' provided in 'id_column' argument, does not exist in 'newdata' DataFrame."
     ]
    }
   ],
   "source": [
    "# Se hace automatico por modelop via CLI / UI. sin embargo para probar el notebook, se puede definir lo siguiente\n",
    "\n",
    "# define the scoring dataset \n",
    "\n",
    "sql = \"\"\"\n",
    "      Select * from tdbacen.CreditRisk_dataset\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "# where to store predictions\n",
    "predictions = {\n",
    "    \"database\": \"tdbacen\",\n",
    "    \"table\": \"CreditRisk_prediction\"\n",
    "}\n",
    "\n",
    "import uuid\n",
    "job_id=str(uuid.uuid4())\n",
    "\n",
    "dataset_info = DatasetInfo(sql=sql,\n",
    "                           entity_key=entity_key,\n",
    "                           feature_names=feature_names,\n",
    "                           target_names=target_names,\n",
    "                           feature_metadata=feature_metadata,\n",
    "                           predictions=predictions)\n",
    "\n",
    "ctx = ModelContext(hyperparams=hyperparams,\n",
    "                   dataset_info=dataset_info,\n",
    "                   artifact_output_path=\"artifacts/\",\n",
    "                   artifact_input_path=\"artifacts/\",\n",
    "                   model_version=\"InDB_v1\",\n",
    "                   model_table=\"model_InDB_v1\",\n",
    "                   job_id=job_id)\n",
    "\n",
    "import scoring\n",
    "scoring.score(context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.from_query(f\"SELECT * FROM tdbacen.CreditRisk_prediction WHERE job_id='{job_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "582e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (Lo dejo comentariado)\n",
    "#os.system(\"rm -f artifacts/*\")\n",
    "\n",
    "#try:\n",
    "#    db_drop_table(\"model_InDB_v1\")\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table(\"scaler_InDB_v1\")\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#try:\n",
    "#    db_drop_table(\"pima_patient_predictions_tmp\")\n",
    "#except: \n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d9a73",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">6. Define la metadata del modelo</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Ahora crear el archivo de configuración.<br>El archivo de dependencias con sus versiones:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f946e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model_modules/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model_modules/requirements.txt\n",
    "teradataml==17.20.0.6\n",
    "teradatamodelops==7.0.3\n",
    "pandas==2.1.4\n",
    "scikit-learn==1.3.2\n",
    "matplotlib==3.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af179c7",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Configure los hiper parametros (Valores x Defecto):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37165d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/config.json\n",
    "{\n",
    "   \"hyperParameters\": {\n",
    "        \"scale_method\":\"STD\",\n",
    "        \"miss_value\":\"KEEP\",\n",
    "        \"global_scale\": \"False\",\n",
    "        \"multiplier\":\"1\",\n",
    "        \"intercept\":\"0\",\n",
    "        \"family\": \"BINOMIAL\", \n",
    "        \"learning_rate\": \"OPTIMAL\",\n",
    "        \"momentum\": 0.80,\n",
    "        \"initial_eta\": 0.05,\n",
    "        \"local_sgd_iterations\": 10,\n",
    "        \"iter_max\": 100,\n",
    "        \"batch_size\": 50,\n",
    "        \"iter_num_no_change\": 5\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4467f",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">La configuración del modelo:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "236decde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/demouser/JT250043/modelops/model_definitions/ModeloRiesgos/model.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $model_local_path/model.json\n",
    "{\n",
    "    \"id\": \"f8df0bec-12d1-4d2d-920f-4448503df82d\",\n",
    "    \"name\": \"Modelo Riesgos\" ,\n",
    "    \"description\": \"Riesgos de creditos\",\n",
    "    \"language\": \"python\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b17a7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">7. Commit and Push to Git to let ModelOps manage</b></p>\n",
    "\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Run the command below to commit and push changes to our forked repository, so ModelOps can fetch the changes to the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45c4ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Unable to create '/home/demouser/JT250043/modelops/.git/index.lock': File exists.\n",
      "\n",
      "Another git process seems to be running in this repository, e.g.\n",
      "an editor opened by 'git commit'. Please make sure all processes\n",
      "are terminated then try again. If it still fails, a git process\n",
      "may have crashed in this repository earlier:\n",
      "remove the file manually to continue.\n"
     ]
    }
   ],
   "source": [
    "!cd $model_local_path/../.. && git add . && git commit -m \"Added Python PIMA InDB GLM demo model 🚀\" && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7cf2a",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Now that changes are pushed, you can make the lifecycle inside <b>ModelOps User Interface</b>, plan for new trainings, evaluations and scorings. Compare models and operationalize into Production with automated Monitoring and alerting capabilities.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a160f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">8. ModelOps full lifecycle till deployment</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88476c06-359f-41ea-b65e-67327de32ed7",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1554f-4c37-4a3a-a333-a96a505dafdf",
   "metadata": {},
   "source": [
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Go and try this Step by yourself. Launch ModelOps from this button below:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046954d-65b1-4939-9ff9-2e12411f3e7e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p><b style = \"font-size:20px;font-family:Arial;color:#00233C\">10. Cleanup</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b210b57-bbc3-485b-a6cc-fbd01f06253f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">If you are done with ModelOps usecase, please uncomment and run the below cleanup section.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bcd8c6-7d73-46e3-8a22-f81c30119256",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"><b>Work Tables</b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e49a6-3cd3-49cd-9cfa-c0342c9d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_drop_table(table_name = \"aoa_byom_models\", schema_name = \"demo_user\")\n",
    "# db_drop_table(table_name = \"pima_patient_predictions\", schema_name = \"demo_user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd8630-f040-4583-af23-d0a30f8901ed",
   "metadata": {},
   "source": [
    "<p style = \"font-size:18px;font-family:Arial;color:#00233C\"> <b>Databases and Tables </b></p>\n",
    "<p style = \"font-size:16px;font-family:Arial;color:#00233C\">The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbc041-b2d5-4926-bae2-0b1cee3d3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../UseCases/run_procedure.py \"call remove_data(\"DEMO_ModelOps\");\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f8688-e4e8-46b8-9bba-2c88d9eefe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d459036-095d-4dc9-a082-1575ada88fa9",
   "metadata": {},
   "source": [
    "[<< Back to GIT Project Setup](./06_ModelOps_GIT_Project_Setup.ipynb) | [Continue to GIT PIMA H2OAutoML >>](./08_ModelOps_GIT_PIMA_Python_H2OAutoML.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b9f6a-8ac5-4890-9b54-1afd8e9c93e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
